{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNFs0BTMkLcni1kGiVrdAd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab으로 진행했습니다~"
      ],
      "metadata": {
        "id": "zdYyi7Ms8pJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVw5FvB48QQX",
        "outputId": "eed3c46a-4e0d-4d41-9bea-3b457a770964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Google Colab에서 GPU 확인\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import InceptionV2  # 업로드된 파일에 따라 import 수정\n",
        "model = InceptionV2(num_classes=10).to(device)\n",
        "# 체크포인트 로드\n",
        "start_epoch, _ = load_checkpoint(model, optimizer)"
      ],
      "metadata": {
        "id": "qVIMVeTq8_dj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # InceptionV2의 입력 크기\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# CIFAR-10 데이터셋 로드\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# DataLoader 설정\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDH_SU-e9Skz",
        "outputId": "340651fe-56be-4bf6-e71a-f225be132aab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "U1ZyIXEQ9U3o"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련용 변수\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "train_accuracies = []"
      ],
      "metadata": {
        "id": "lsOK2R3u-B91"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 루프\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 정확도 기록\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # 배치마다 출력\n",
        "        if (i + 1) % 10 == 0:  # 매 10배치마다 출력\n",
        "            batch_loss = running_loss / (i + 1)\n",
        "            batch_accuracy = 100 * correct / total\n",
        "            print(f\"Batch [{i+1}/{len(train_loader)}], Loss: {batch_loss:.4f}, Accuracy: {batch_accuracy:.2f}%\")\n",
        "\n",
        "    # Epoch 결과 저장\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_OKdGCN-kI_",
        "outputId": "5651ef8f-d5b8-4836-a668-87b5aae49715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n",
            "Batch [10/1563], Loss: 2.3154, Accuracy: 9.38%\n",
            "Batch [20/1563], Loss: 2.3111, Accuracy: 10.62%\n",
            "Batch [30/1563], Loss: 2.3064, Accuracy: 10.21%\n",
            "Batch [40/1563], Loss: 2.3064, Accuracy: 10.16%\n",
            "Batch [50/1563], Loss: 2.3065, Accuracy: 9.38%\n",
            "Batch [60/1563], Loss: 2.3066, Accuracy: 9.64%\n",
            "Batch [70/1563], Loss: 2.3063, Accuracy: 9.69%\n",
            "Batch [80/1563], Loss: 2.3061, Accuracy: 9.38%\n",
            "Batch [90/1563], Loss: 2.3056, Accuracy: 9.72%\n",
            "Batch [100/1563], Loss: 2.3055, Accuracy: 9.56%\n",
            "Batch [110/1563], Loss: 2.3059, Accuracy: 9.57%\n",
            "Batch [120/1563], Loss: 2.3044, Accuracy: 9.79%\n",
            "Batch [130/1563], Loss: 2.3051, Accuracy: 9.88%\n",
            "Batch [140/1563], Loss: 2.3029, Accuracy: 10.11%\n",
            "Batch [150/1563], Loss: 2.2990, Accuracy: 10.50%\n",
            "Batch [160/1563], Loss: 2.2980, Accuracy: 10.57%\n",
            "Batch [170/1563], Loss: 2.2963, Accuracy: 10.61%\n",
            "Batch [180/1563], Loss: 2.2909, Accuracy: 11.23%\n",
            "Batch [190/1563], Loss: 2.2830, Accuracy: 11.56%\n",
            "Batch [200/1563], Loss: 2.2769, Accuracy: 11.94%\n",
            "Batch [210/1563], Loss: 2.2740, Accuracy: 12.19%\n",
            "Batch [220/1563], Loss: 2.2671, Accuracy: 12.66%\n",
            "Batch [230/1563], Loss: 2.2640, Accuracy: 13.06%\n",
            "Batch [240/1563], Loss: 2.2577, Accuracy: 13.32%\n",
            "Batch [250/1563], Loss: 2.2529, Accuracy: 13.59%\n",
            "Batch [260/1563], Loss: 2.2492, Accuracy: 13.76%\n",
            "Batch [270/1563], Loss: 2.2454, Accuracy: 14.09%\n",
            "Batch [280/1563], Loss: 2.2398, Accuracy: 14.25%\n",
            "Batch [290/1563], Loss: 2.2346, Accuracy: 14.50%\n",
            "Batch [300/1563], Loss: 2.2307, Accuracy: 14.66%\n",
            "Batch [310/1563], Loss: 2.2243, Accuracy: 14.93%\n",
            "Batch [320/1563], Loss: 2.2222, Accuracy: 15.07%\n",
            "Batch [330/1563], Loss: 2.2196, Accuracy: 15.19%\n",
            "Batch [340/1563], Loss: 2.2149, Accuracy: 15.41%\n",
            "Batch [350/1563], Loss: 2.2131, Accuracy: 15.54%\n",
            "Batch [360/1563], Loss: 2.2101, Accuracy: 15.69%\n",
            "Batch [370/1563], Loss: 2.2092, Accuracy: 15.78%\n",
            "Batch [380/1563], Loss: 2.2071, Accuracy: 15.89%\n",
            "Batch [390/1563], Loss: 2.2026, Accuracy: 16.10%\n",
            "Batch [400/1563], Loss: 2.2005, Accuracy: 16.22%\n",
            "Batch [410/1563], Loss: 2.1964, Accuracy: 16.48%\n",
            "Batch [420/1563], Loss: 2.1955, Accuracy: 16.53%\n",
            "Batch [430/1563], Loss: 2.1929, Accuracy: 16.70%\n",
            "Batch [440/1563], Loss: 2.1906, Accuracy: 16.75%\n",
            "Batch [450/1563], Loss: 2.1872, Accuracy: 16.96%\n",
            "Batch [460/1563], Loss: 2.1866, Accuracy: 17.09%\n",
            "Batch [470/1563], Loss: 2.1832, Accuracy: 17.23%\n",
            "Batch [480/1563], Loss: 2.1796, Accuracy: 17.38%\n",
            "Batch [490/1563], Loss: 2.1768, Accuracy: 17.47%\n",
            "Batch [500/1563], Loss: 2.1738, Accuracy: 17.67%\n",
            "Batch [510/1563], Loss: 2.1720, Accuracy: 17.68%\n",
            "Batch [520/1563], Loss: 2.1695, Accuracy: 17.78%\n",
            "Batch [530/1563], Loss: 2.1659, Accuracy: 17.90%\n",
            "Batch [540/1563], Loss: 2.1638, Accuracy: 18.04%\n",
            "Batch [550/1563], Loss: 2.1613, Accuracy: 18.14%\n",
            "Batch [560/1563], Loss: 2.1578, Accuracy: 18.28%\n",
            "Batch [570/1563], Loss: 2.1557, Accuracy: 18.34%\n",
            "Batch [580/1563], Loss: 2.1536, Accuracy: 18.42%\n",
            "Batch [590/1563], Loss: 2.1509, Accuracy: 18.62%\n",
            "Batch [600/1563], Loss: 2.1479, Accuracy: 18.77%\n",
            "Batch [610/1563], Loss: 2.1450, Accuracy: 18.90%\n",
            "Batch [620/1563], Loss: 2.1423, Accuracy: 18.99%\n",
            "Batch [630/1563], Loss: 2.1405, Accuracy: 19.09%\n",
            "Batch [640/1563], Loss: 2.1374, Accuracy: 19.22%\n",
            "Batch [650/1563], Loss: 2.1350, Accuracy: 19.33%\n",
            "Batch [660/1563], Loss: 2.1324, Accuracy: 19.35%\n",
            "Batch [670/1563], Loss: 2.1288, Accuracy: 19.48%\n",
            "Batch [680/1563], Loss: 2.1254, Accuracy: 19.66%\n",
            "Batch [690/1563], Loss: 2.1237, Accuracy: 19.77%\n",
            "Batch [700/1563], Loss: 2.1211, Accuracy: 19.90%\n",
            "Batch [710/1563], Loss: 2.1197, Accuracy: 19.92%\n",
            "Batch [720/1563], Loss: 2.1179, Accuracy: 20.04%\n",
            "Batch [730/1563], Loss: 2.1162, Accuracy: 20.07%\n",
            "Batch [740/1563], Loss: 2.1126, Accuracy: 20.18%\n",
            "Batch [750/1563], Loss: 2.1105, Accuracy: 20.25%\n",
            "Batch [760/1563], Loss: 2.1068, Accuracy: 20.41%\n",
            "Batch [770/1563], Loss: 2.1042, Accuracy: 20.51%\n",
            "Batch [780/1563], Loss: 2.1019, Accuracy: 20.58%\n",
            "Batch [790/1563], Loss: 2.0991, Accuracy: 20.72%\n",
            "Batch [800/1563], Loss: 2.0962, Accuracy: 20.83%\n",
            "Batch [810/1563], Loss: 2.0929, Accuracy: 21.00%\n",
            "Batch [820/1563], Loss: 2.0893, Accuracy: 21.13%\n",
            "Batch [830/1563], Loss: 2.0869, Accuracy: 21.25%\n",
            "Batch [840/1563], Loss: 2.0848, Accuracy: 21.34%\n",
            "Batch [850/1563], Loss: 2.0813, Accuracy: 21.51%\n",
            "Batch [860/1563], Loss: 2.0784, Accuracy: 21.62%\n",
            "Batch [870/1563], Loss: 2.0758, Accuracy: 21.72%\n",
            "Batch [880/1563], Loss: 2.0741, Accuracy: 21.84%\n",
            "Batch [890/1563], Loss: 2.0716, Accuracy: 21.91%\n",
            "Batch [900/1563], Loss: 2.0688, Accuracy: 22.02%\n",
            "Batch [910/1563], Loss: 2.0661, Accuracy: 22.11%\n",
            "Batch [920/1563], Loss: 2.0636, Accuracy: 22.22%\n",
            "Batch [930/1563], Loss: 2.0600, Accuracy: 22.40%\n",
            "Batch [940/1563], Loss: 2.0575, Accuracy: 22.51%\n",
            "Batch [950/1563], Loss: 2.0554, Accuracy: 22.62%\n",
            "Batch [960/1563], Loss: 2.0532, Accuracy: 22.74%\n",
            "Batch [970/1563], Loss: 2.0510, Accuracy: 22.84%\n",
            "Batch [980/1563], Loss: 2.0485, Accuracy: 22.98%\n",
            "Batch [990/1563], Loss: 2.0456, Accuracy: 23.07%\n",
            "Batch [1000/1563], Loss: 2.0431, Accuracy: 23.15%\n",
            "Batch [1010/1563], Loss: 2.0410, Accuracy: 23.26%\n",
            "Batch [1020/1563], Loss: 2.0385, Accuracy: 23.35%\n",
            "Batch [1030/1563], Loss: 2.0353, Accuracy: 23.45%\n",
            "Batch [1040/1563], Loss: 2.0327, Accuracy: 23.58%\n",
            "Batch [1050/1563], Loss: 2.0313, Accuracy: 23.61%\n",
            "Batch [1060/1563], Loss: 2.0289, Accuracy: 23.71%\n",
            "Batch [1070/1563], Loss: 2.0271, Accuracy: 23.78%\n",
            "Batch [1080/1563], Loss: 2.0236, Accuracy: 23.92%\n",
            "Batch [1090/1563], Loss: 2.0197, Accuracy: 24.12%\n",
            "Batch [1100/1563], Loss: 2.0172, Accuracy: 24.22%\n",
            "Batch [1110/1563], Loss: 2.0148, Accuracy: 24.33%\n",
            "Batch [1120/1563], Loss: 2.0117, Accuracy: 24.45%\n",
            "Batch [1130/1563], Loss: 2.0092, Accuracy: 24.58%\n",
            "Batch [1140/1563], Loss: 2.0074, Accuracy: 24.65%\n",
            "Batch [1150/1563], Loss: 2.0045, Accuracy: 24.77%\n",
            "Batch [1160/1563], Loss: 2.0020, Accuracy: 24.86%\n",
            "Batch [1170/1563], Loss: 2.0001, Accuracy: 24.98%\n",
            "Batch [1180/1563], Loss: 1.9986, Accuracy: 25.07%\n",
            "Batch [1190/1563], Loss: 1.9962, Accuracy: 25.17%\n",
            "Batch [1200/1563], Loss: 1.9938, Accuracy: 25.28%\n",
            "Batch [1210/1563], Loss: 1.9930, Accuracy: 25.32%\n",
            "Batch [1220/1563], Loss: 1.9909, Accuracy: 25.40%\n",
            "Batch [1230/1563], Loss: 1.9883, Accuracy: 25.48%\n",
            "Batch [1240/1563], Loss: 1.9857, Accuracy: 25.60%\n",
            "Batch [1250/1563], Loss: 1.9839, Accuracy: 25.68%\n",
            "Batch [1260/1563], Loss: 1.9819, Accuracy: 25.78%\n",
            "Batch [1270/1563], Loss: 1.9797, Accuracy: 25.86%\n",
            "Batch [1280/1563], Loss: 1.9766, Accuracy: 26.00%\n",
            "Batch [1290/1563], Loss: 1.9743, Accuracy: 26.11%\n",
            "Batch [1300/1563], Loss: 1.9731, Accuracy: 26.17%\n",
            "Batch [1310/1563], Loss: 1.9717, Accuracy: 26.23%\n",
            "Batch [1320/1563], Loss: 1.9697, Accuracy: 26.29%\n",
            "Batch [1330/1563], Loss: 1.9681, Accuracy: 26.38%\n",
            "Batch [1340/1563], Loss: 1.9658, Accuracy: 26.46%\n",
            "Batch [1350/1563], Loss: 1.9632, Accuracy: 26.55%\n",
            "Batch [1360/1563], Loss: 1.9607, Accuracy: 26.66%\n",
            "Batch [1370/1563], Loss: 1.9589, Accuracy: 26.75%\n",
            "Batch [1380/1563], Loss: 1.9564, Accuracy: 26.84%\n",
            "Batch [1390/1563], Loss: 1.9538, Accuracy: 26.95%\n",
            "Batch [1400/1563], Loss: 1.9520, Accuracy: 27.02%\n",
            "Batch [1410/1563], Loss: 1.9499, Accuracy: 27.12%\n",
            "Batch [1420/1563], Loss: 1.9478, Accuracy: 27.20%\n",
            "Batch [1430/1563], Loss: 1.9455, Accuracy: 27.31%\n",
            "Batch [1440/1563], Loss: 1.9433, Accuracy: 27.40%\n",
            "Batch [1450/1563], Loss: 1.9410, Accuracy: 27.50%\n",
            "Batch [1460/1563], Loss: 1.9383, Accuracy: 27.62%\n",
            "Batch [1470/1563], Loss: 1.9363, Accuracy: 27.72%\n",
            "Batch [1480/1563], Loss: 1.9337, Accuracy: 27.82%\n",
            "Batch [1490/1563], Loss: 1.9310, Accuracy: 27.93%\n",
            "Batch [1500/1563], Loss: 1.9289, Accuracy: 28.02%\n",
            "Batch [1510/1563], Loss: 1.9269, Accuracy: 28.10%\n",
            "Batch [1520/1563], Loss: 1.9246, Accuracy: 28.21%\n",
            "Batch [1530/1563], Loss: 1.9229, Accuracy: 28.28%\n",
            "Batch [1540/1563], Loss: 1.9206, Accuracy: 28.38%\n",
            "Batch [1550/1563], Loss: 1.9191, Accuracy: 28.45%\n",
            "Batch [1560/1563], Loss: 1.9169, Accuracy: 28.55%\n",
            "Epoch [1/10] - Loss: 1.9163, Accuracy: 28.57%\n",
            "Epoch [2/10]\n",
            "Batch [10/1563], Loss: 1.6111, Accuracy: 42.19%\n",
            "Batch [20/1563], Loss: 1.5416, Accuracy: 44.06%\n",
            "Batch [30/1563], Loss: 1.5254, Accuracy: 45.10%\n",
            "Batch [40/1563], Loss: 1.5558, Accuracy: 44.84%\n",
            "Batch [50/1563], Loss: 1.5401, Accuracy: 45.06%\n",
            "Batch [60/1563], Loss: 1.5496, Accuracy: 44.48%\n",
            "Batch [70/1563], Loss: 1.5463, Accuracy: 44.78%\n",
            "Batch [80/1563], Loss: 1.5485, Accuracy: 44.10%\n",
            "Batch [90/1563], Loss: 1.5343, Accuracy: 44.55%\n",
            "Batch [100/1563], Loss: 1.5272, Accuracy: 45.25%\n",
            "Batch [110/1563], Loss: 1.5318, Accuracy: 45.37%\n",
            "Batch [120/1563], Loss: 1.5314, Accuracy: 45.34%\n",
            "Batch [130/1563], Loss: 1.5391, Accuracy: 45.05%\n",
            "Batch [140/1563], Loss: 1.5409, Accuracy: 45.09%\n",
            "Batch [150/1563], Loss: 1.5373, Accuracy: 45.17%\n",
            "Batch [160/1563], Loss: 1.5372, Accuracy: 45.14%\n",
            "Batch [170/1563], Loss: 1.5399, Accuracy: 44.94%\n",
            "Batch [180/1563], Loss: 1.5399, Accuracy: 44.88%\n",
            "Batch [190/1563], Loss: 1.5378, Accuracy: 44.93%\n",
            "Batch [200/1563], Loss: 1.5368, Accuracy: 44.89%\n",
            "Batch [210/1563], Loss: 1.5314, Accuracy: 45.13%\n",
            "Batch [220/1563], Loss: 1.5296, Accuracy: 45.38%\n",
            "Batch [230/1563], Loss: 1.5230, Accuracy: 45.42%\n",
            "Batch [240/1563], Loss: 1.5185, Accuracy: 45.68%\n",
            "Batch [250/1563], Loss: 1.5157, Accuracy: 45.65%\n",
            "Batch [260/1563], Loss: 1.5160, Accuracy: 45.58%\n",
            "Batch [270/1563], Loss: 1.5166, Accuracy: 45.41%\n",
            "Batch [280/1563], Loss: 1.5151, Accuracy: 45.41%\n",
            "Batch [290/1563], Loss: 1.5162, Accuracy: 45.59%\n",
            "Batch [300/1563], Loss: 1.5129, Accuracy: 45.67%\n",
            "Batch [310/1563], Loss: 1.5085, Accuracy: 45.76%\n",
            "Batch [320/1563], Loss: 1.5044, Accuracy: 45.89%\n",
            "Batch [330/1563], Loss: 1.4993, Accuracy: 46.05%\n",
            "Batch [340/1563], Loss: 1.4996, Accuracy: 45.91%\n",
            "Batch [350/1563], Loss: 1.4967, Accuracy: 46.04%\n",
            "Batch [360/1563], Loss: 1.4935, Accuracy: 46.16%\n",
            "Batch [370/1563], Loss: 1.4935, Accuracy: 46.30%\n",
            "Batch [380/1563], Loss: 1.4897, Accuracy: 46.43%\n",
            "Batch [390/1563], Loss: 1.4923, Accuracy: 46.40%\n",
            "Batch [400/1563], Loss: 1.4917, Accuracy: 46.47%\n",
            "Batch [410/1563], Loss: 1.4910, Accuracy: 46.55%\n",
            "Batch [420/1563], Loss: 1.4889, Accuracy: 46.67%\n",
            "Batch [430/1563], Loss: 1.4866, Accuracy: 46.73%\n",
            "Batch [440/1563], Loss: 1.4869, Accuracy: 46.83%\n",
            "Batch [450/1563], Loss: 1.4874, Accuracy: 46.80%\n",
            "Batch [460/1563], Loss: 1.4854, Accuracy: 46.92%\n",
            "Batch [470/1563], Loss: 1.4864, Accuracy: 46.80%\n",
            "Batch [480/1563], Loss: 1.4842, Accuracy: 46.90%\n",
            "Batch [490/1563], Loss: 1.4828, Accuracy: 46.94%\n",
            "Batch [500/1563], Loss: 1.4831, Accuracy: 46.92%\n",
            "Batch [510/1563], Loss: 1.4811, Accuracy: 46.92%\n",
            "Batch [520/1563], Loss: 1.4793, Accuracy: 47.02%\n",
            "Batch [530/1563], Loss: 1.4764, Accuracy: 47.12%\n",
            "Batch [540/1563], Loss: 1.4739, Accuracy: 47.22%\n",
            "Batch [550/1563], Loss: 1.4715, Accuracy: 47.30%\n",
            "Batch [560/1563], Loss: 1.4705, Accuracy: 47.33%\n",
            "Batch [570/1563], Loss: 1.4693, Accuracy: 47.38%\n",
            "Batch [580/1563], Loss: 1.4693, Accuracy: 47.32%\n",
            "Batch [590/1563], Loss: 1.4674, Accuracy: 47.39%\n",
            "Batch [600/1563], Loss: 1.4663, Accuracy: 47.37%\n",
            "Batch [610/1563], Loss: 1.4664, Accuracy: 47.41%\n",
            "Batch [620/1563], Loss: 1.4674, Accuracy: 47.36%\n",
            "Batch [630/1563], Loss: 1.4667, Accuracy: 47.35%\n",
            "Batch [640/1563], Loss: 1.4661, Accuracy: 47.38%\n",
            "Batch [650/1563], Loss: 1.4642, Accuracy: 47.44%\n",
            "Batch [660/1563], Loss: 1.4631, Accuracy: 47.52%\n",
            "Batch [670/1563], Loss: 1.4609, Accuracy: 47.62%\n",
            "Batch [680/1563], Loss: 1.4595, Accuracy: 47.65%\n",
            "Batch [690/1563], Loss: 1.4601, Accuracy: 47.63%\n",
            "Batch [700/1563], Loss: 1.4586, Accuracy: 47.64%\n",
            "Batch [710/1563], Loss: 1.4582, Accuracy: 47.65%\n",
            "Batch [720/1563], Loss: 1.4568, Accuracy: 47.74%\n",
            "Batch [730/1563], Loss: 1.4538, Accuracy: 47.84%\n",
            "Batch [740/1563], Loss: 1.4521, Accuracy: 47.93%\n",
            "Batch [750/1563], Loss: 1.4493, Accuracy: 47.99%\n",
            "Batch [760/1563], Loss: 1.4476, Accuracy: 48.04%\n",
            "Batch [770/1563], Loss: 1.4451, Accuracy: 48.14%\n",
            "Batch [780/1563], Loss: 1.4448, Accuracy: 48.15%\n",
            "Batch [790/1563], Loss: 1.4438, Accuracy: 48.17%\n",
            "Batch [800/1563], Loss: 1.4424, Accuracy: 48.18%\n",
            "Batch [810/1563], Loss: 1.4426, Accuracy: 48.22%\n",
            "Batch [820/1563], Loss: 1.4413, Accuracy: 48.22%\n",
            "Batch [830/1563], Loss: 1.4392, Accuracy: 48.30%\n",
            "Batch [840/1563], Loss: 1.4380, Accuracy: 48.32%\n",
            "Batch [850/1563], Loss: 1.4373, Accuracy: 48.35%\n",
            "Batch [860/1563], Loss: 1.4355, Accuracy: 48.44%\n",
            "Batch [870/1563], Loss: 1.4335, Accuracy: 48.52%\n",
            "Batch [880/1563], Loss: 1.4326, Accuracy: 48.56%\n",
            "Batch [890/1563], Loss: 1.4328, Accuracy: 48.53%\n",
            "Batch [900/1563], Loss: 1.4308, Accuracy: 48.58%\n",
            "Batch [910/1563], Loss: 1.4285, Accuracy: 48.65%\n",
            "Batch [920/1563], Loss: 1.4273, Accuracy: 48.69%\n",
            "Batch [930/1563], Loss: 1.4271, Accuracy: 48.69%\n",
            "Batch [940/1563], Loss: 1.4265, Accuracy: 48.73%\n",
            "Batch [950/1563], Loss: 1.4261, Accuracy: 48.75%\n",
            "Batch [960/1563], Loss: 1.4245, Accuracy: 48.80%\n",
            "Batch [970/1563], Loss: 1.4237, Accuracy: 48.85%\n",
            "Batch [980/1563], Loss: 1.4231, Accuracy: 48.86%\n",
            "Batch [990/1563], Loss: 1.4226, Accuracy: 48.87%\n",
            "Batch [1000/1563], Loss: 1.4221, Accuracy: 48.89%\n",
            "Batch [1010/1563], Loss: 1.4203, Accuracy: 48.95%\n",
            "Batch [1020/1563], Loss: 1.4197, Accuracy: 48.97%\n",
            "Batch [1030/1563], Loss: 1.4181, Accuracy: 49.06%\n",
            "Batch [1040/1563], Loss: 1.4158, Accuracy: 49.12%\n",
            "Batch [1050/1563], Loss: 1.4150, Accuracy: 49.19%\n",
            "Batch [1060/1563], Loss: 1.4147, Accuracy: 49.21%\n",
            "Batch [1070/1563], Loss: 1.4135, Accuracy: 49.23%\n",
            "Batch [1080/1563], Loss: 1.4125, Accuracy: 49.29%\n",
            "Batch [1090/1563], Loss: 1.4116, Accuracy: 49.35%\n",
            "Batch [1100/1563], Loss: 1.4093, Accuracy: 49.44%\n",
            "Batch [1110/1563], Loss: 1.4084, Accuracy: 49.50%\n",
            "Batch [1120/1563], Loss: 1.4080, Accuracy: 49.54%\n",
            "Batch [1130/1563], Loss: 1.4068, Accuracy: 49.56%\n",
            "Batch [1140/1563], Loss: 1.4062, Accuracy: 49.57%\n",
            "Batch [1150/1563], Loss: 1.4064, Accuracy: 49.62%\n",
            "Batch [1160/1563], Loss: 1.4059, Accuracy: 49.63%\n",
            "Batch [1170/1563], Loss: 1.4043, Accuracy: 49.67%\n",
            "Batch [1180/1563], Loss: 1.4031, Accuracy: 49.72%\n",
            "Batch [1190/1563], Loss: 1.4008, Accuracy: 49.82%\n",
            "Batch [1200/1563], Loss: 1.4001, Accuracy: 49.89%\n",
            "Batch [1210/1563], Loss: 1.3997, Accuracy: 49.90%\n",
            "Batch [1220/1563], Loss: 1.3984, Accuracy: 49.95%\n",
            "Batch [1230/1563], Loss: 1.3965, Accuracy: 50.01%\n",
            "Batch [1240/1563], Loss: 1.3960, Accuracy: 50.03%\n",
            "Batch [1250/1563], Loss: 1.3945, Accuracy: 50.06%\n",
            "Batch [1260/1563], Loss: 1.3937, Accuracy: 50.09%\n",
            "Batch [1270/1563], Loss: 1.3926, Accuracy: 50.13%\n",
            "Batch [1280/1563], Loss: 1.3916, Accuracy: 50.18%\n",
            "Batch [1290/1563], Loss: 1.3910, Accuracy: 50.19%\n",
            "Batch [1300/1563], Loss: 1.3895, Accuracy: 50.27%\n",
            "Batch [1310/1563], Loss: 1.3872, Accuracy: 50.38%\n",
            "Batch [1320/1563], Loss: 1.3865, Accuracy: 50.44%\n",
            "Batch [1330/1563], Loss: 1.3856, Accuracy: 50.47%\n",
            "Batch [1340/1563], Loss: 1.3849, Accuracy: 50.51%\n",
            "Batch [1350/1563], Loss: 1.3840, Accuracy: 50.54%\n",
            "Batch [1360/1563], Loss: 1.3827, Accuracy: 50.60%\n",
            "Batch [1370/1563], Loss: 1.3814, Accuracy: 50.64%\n",
            "Batch [1380/1563], Loss: 1.3800, Accuracy: 50.70%\n",
            "Batch [1390/1563], Loss: 1.3792, Accuracy: 50.76%\n",
            "Batch [1400/1563], Loss: 1.3779, Accuracy: 50.82%\n",
            "Batch [1410/1563], Loss: 1.3769, Accuracy: 50.85%\n",
            "Batch [1420/1563], Loss: 1.3754, Accuracy: 50.90%\n",
            "Batch [1430/1563], Loss: 1.3745, Accuracy: 50.94%\n",
            "Batch [1440/1563], Loss: 1.3736, Accuracy: 50.97%\n",
            "Batch [1450/1563], Loss: 1.3727, Accuracy: 51.01%\n",
            "Batch [1460/1563], Loss: 1.3718, Accuracy: 51.06%\n",
            "Batch [1470/1563], Loss: 1.3711, Accuracy: 51.10%\n",
            "Batch [1480/1563], Loss: 1.3710, Accuracy: 51.14%\n",
            "Batch [1490/1563], Loss: 1.3701, Accuracy: 51.18%\n",
            "Batch [1500/1563], Loss: 1.3690, Accuracy: 51.21%\n",
            "Batch [1510/1563], Loss: 1.3677, Accuracy: 51.27%\n",
            "Batch [1520/1563], Loss: 1.3662, Accuracy: 51.32%\n",
            "Batch [1530/1563], Loss: 1.3658, Accuracy: 51.35%\n",
            "Batch [1540/1563], Loss: 1.3648, Accuracy: 51.37%\n",
            "Batch [1550/1563], Loss: 1.3640, Accuracy: 51.40%\n",
            "Batch [1560/1563], Loss: 1.3626, Accuracy: 51.46%\n",
            "Epoch [2/10] - Loss: 1.3624, Accuracy: 51.46%\n",
            "Epoch [3/10]\n",
            "Batch [10/1563], Loss: 1.1331, Accuracy: 62.50%\n",
            "Batch [20/1563], Loss: 1.1498, Accuracy: 61.25%\n",
            "Batch [30/1563], Loss: 1.1804, Accuracy: 58.54%\n",
            "Batch [40/1563], Loss: 1.2002, Accuracy: 57.34%\n",
            "Batch [50/1563], Loss: 1.2132, Accuracy: 56.62%\n",
            "Batch [60/1563], Loss: 1.2273, Accuracy: 56.82%\n",
            "Batch [70/1563], Loss: 1.2131, Accuracy: 57.23%\n",
            "Batch [80/1563], Loss: 1.2100, Accuracy: 56.88%\n",
            "Batch [90/1563], Loss: 1.2088, Accuracy: 57.15%\n",
            "Batch [100/1563], Loss: 1.2019, Accuracy: 57.09%\n",
            "Batch [110/1563], Loss: 1.2039, Accuracy: 57.24%\n",
            "Batch [120/1563], Loss: 1.1957, Accuracy: 57.58%\n",
            "Batch [130/1563], Loss: 1.1892, Accuracy: 57.74%\n",
            "Batch [140/1563], Loss: 1.1921, Accuracy: 57.72%\n",
            "Batch [150/1563], Loss: 1.1937, Accuracy: 57.67%\n",
            "Batch [160/1563], Loss: 1.1929, Accuracy: 57.77%\n",
            "Batch [170/1563], Loss: 1.1928, Accuracy: 57.70%\n",
            "Batch [180/1563], Loss: 1.1894, Accuracy: 57.86%\n",
            "Batch [190/1563], Loss: 1.1871, Accuracy: 57.85%\n",
            "Batch [200/1563], Loss: 1.1905, Accuracy: 57.67%\n",
            "Batch [210/1563], Loss: 1.1890, Accuracy: 57.62%\n",
            "Batch [220/1563], Loss: 1.1905, Accuracy: 57.56%\n",
            "Batch [230/1563], Loss: 1.1857, Accuracy: 57.88%\n",
            "Batch [240/1563], Loss: 1.1934, Accuracy: 57.75%\n",
            "Batch [250/1563], Loss: 1.1951, Accuracy: 57.59%\n",
            "Batch [260/1563], Loss: 1.1983, Accuracy: 57.52%\n",
            "Batch [270/1563], Loss: 1.1973, Accuracy: 57.51%\n",
            "Batch [280/1563], Loss: 1.1949, Accuracy: 57.71%\n",
            "Batch [290/1563], Loss: 1.1925, Accuracy: 57.76%\n",
            "Batch [300/1563], Loss: 1.1943, Accuracy: 57.68%\n",
            "Batch [310/1563], Loss: 1.1935, Accuracy: 57.69%\n",
            "Batch [320/1563], Loss: 1.1906, Accuracy: 57.78%\n",
            "Batch [330/1563], Loss: 1.1898, Accuracy: 57.84%\n",
            "Batch [340/1563], Loss: 1.1907, Accuracy: 57.78%\n",
            "Batch [350/1563], Loss: 1.1904, Accuracy: 57.82%\n",
            "Batch [360/1563], Loss: 1.1874, Accuracy: 57.96%\n",
            "Batch [370/1563], Loss: 1.1890, Accuracy: 57.81%\n",
            "Batch [380/1563], Loss: 1.1836, Accuracy: 58.02%\n",
            "Batch [390/1563], Loss: 1.1847, Accuracy: 57.98%\n",
            "Batch [400/1563], Loss: 1.1813, Accuracy: 58.14%\n",
            "Batch [410/1563], Loss: 1.1823, Accuracy: 58.22%\n",
            "Batch [420/1563], Loss: 1.1837, Accuracy: 58.15%\n",
            "Batch [430/1563], Loss: 1.1814, Accuracy: 58.22%\n",
            "Batch [440/1563], Loss: 1.1815, Accuracy: 58.22%\n",
            "Batch [450/1563], Loss: 1.1817, Accuracy: 58.20%\n",
            "Batch [460/1563], Loss: 1.1811, Accuracy: 58.22%\n",
            "Batch [470/1563], Loss: 1.1816, Accuracy: 58.28%\n",
            "Batch [480/1563], Loss: 1.1820, Accuracy: 58.22%\n",
            "Batch [490/1563], Loss: 1.1815, Accuracy: 58.24%\n",
            "Batch [500/1563], Loss: 1.1829, Accuracy: 58.24%\n",
            "Batch [510/1563], Loss: 1.1810, Accuracy: 58.37%\n",
            "Batch [520/1563], Loss: 1.1829, Accuracy: 58.30%\n",
            "Batch [530/1563], Loss: 1.1840, Accuracy: 58.34%\n",
            "Batch [540/1563], Loss: 1.1827, Accuracy: 58.40%\n",
            "Batch [550/1563], Loss: 1.1815, Accuracy: 58.34%\n",
            "Batch [560/1563], Loss: 1.1815, Accuracy: 58.34%\n",
            "Batch [570/1563], Loss: 1.1805, Accuracy: 58.39%\n",
            "Batch [580/1563], Loss: 1.1814, Accuracy: 58.35%\n",
            "Batch [590/1563], Loss: 1.1812, Accuracy: 58.43%\n",
            "Batch [600/1563], Loss: 1.1784, Accuracy: 58.55%\n",
            "Batch [610/1563], Loss: 1.1749, Accuracy: 58.69%\n",
            "Batch [620/1563], Loss: 1.1734, Accuracy: 58.74%\n",
            "Batch [630/1563], Loss: 1.1733, Accuracy: 58.75%\n",
            "Batch [640/1563], Loss: 1.1722, Accuracy: 58.76%\n",
            "Batch [650/1563], Loss: 1.1694, Accuracy: 58.88%\n",
            "Batch [660/1563], Loss: 1.1710, Accuracy: 58.81%\n",
            "Batch [670/1563], Loss: 1.1714, Accuracy: 58.84%\n",
            "Batch [680/1563], Loss: 1.1702, Accuracy: 58.92%\n",
            "Batch [690/1563], Loss: 1.1699, Accuracy: 58.91%\n",
            "Batch [700/1563], Loss: 1.1708, Accuracy: 58.87%\n",
            "Batch [710/1563], Loss: 1.1697, Accuracy: 58.90%\n",
            "Batch [720/1563], Loss: 1.1706, Accuracy: 58.85%\n",
            "Batch [730/1563], Loss: 1.1687, Accuracy: 58.93%\n",
            "Batch [740/1563], Loss: 1.1679, Accuracy: 58.94%\n",
            "Batch [750/1563], Loss: 1.1664, Accuracy: 58.98%\n",
            "Batch [760/1563], Loss: 1.1655, Accuracy: 59.01%\n",
            "Batch [770/1563], Loss: 1.1640, Accuracy: 59.06%\n",
            "Batch [780/1563], Loss: 1.1634, Accuracy: 59.12%\n",
            "Batch [790/1563], Loss: 1.1622, Accuracy: 59.20%\n",
            "Batch [800/1563], Loss: 1.1602, Accuracy: 59.29%\n",
            "Batch [810/1563], Loss: 1.1601, Accuracy: 59.30%\n",
            "Batch [820/1563], Loss: 1.1596, Accuracy: 59.35%\n",
            "Batch [830/1563], Loss: 1.1581, Accuracy: 59.41%\n",
            "Batch [840/1563], Loss: 1.1572, Accuracy: 59.46%\n",
            "Batch [850/1563], Loss: 1.1560, Accuracy: 59.51%\n",
            "Batch [860/1563], Loss: 1.1556, Accuracy: 59.51%\n",
            "Batch [870/1563], Loss: 1.1550, Accuracy: 59.53%\n",
            "Batch [880/1563], Loss: 1.1549, Accuracy: 59.49%\n",
            "Batch [890/1563], Loss: 1.1526, Accuracy: 59.57%\n",
            "Batch [900/1563], Loss: 1.1517, Accuracy: 59.60%\n",
            "Batch [910/1563], Loss: 1.1518, Accuracy: 59.62%\n",
            "Batch [920/1563], Loss: 1.1509, Accuracy: 59.68%\n",
            "Batch [930/1563], Loss: 1.1497, Accuracy: 59.74%\n",
            "Batch [940/1563], Loss: 1.1491, Accuracy: 59.77%\n",
            "Batch [950/1563], Loss: 1.1480, Accuracy: 59.82%\n",
            "Batch [960/1563], Loss: 1.1479, Accuracy: 59.80%\n",
            "Batch [970/1563], Loss: 1.1480, Accuracy: 59.80%\n",
            "Batch [980/1563], Loss: 1.1475, Accuracy: 59.78%\n",
            "Batch [990/1563], Loss: 1.1467, Accuracy: 59.78%\n",
            "Batch [1000/1563], Loss: 1.1448, Accuracy: 59.84%\n",
            "Batch [1010/1563], Loss: 1.1434, Accuracy: 59.89%\n",
            "Batch [1020/1563], Loss: 1.1436, Accuracy: 59.90%\n",
            "Batch [1030/1563], Loss: 1.1444, Accuracy: 59.88%\n",
            "Batch [1040/1563], Loss: 1.1430, Accuracy: 59.95%\n",
            "Batch [1050/1563], Loss: 1.1435, Accuracy: 59.94%\n",
            "Batch [1060/1563], Loss: 1.1429, Accuracy: 59.94%\n",
            "Batch [1070/1563], Loss: 1.1419, Accuracy: 59.99%\n",
            "Batch [1080/1563], Loss: 1.1415, Accuracy: 60.00%\n",
            "Batch [1090/1563], Loss: 1.1394, Accuracy: 60.07%\n",
            "Batch [1100/1563], Loss: 1.1386, Accuracy: 60.11%\n",
            "Batch [1110/1563], Loss: 1.1379, Accuracy: 60.11%\n",
            "Batch [1120/1563], Loss: 1.1375, Accuracy: 60.14%\n",
            "Batch [1130/1563], Loss: 1.1369, Accuracy: 60.15%\n",
            "Batch [1140/1563], Loss: 1.1368, Accuracy: 60.16%\n",
            "Batch [1150/1563], Loss: 1.1367, Accuracy: 60.17%\n",
            "Batch [1160/1563], Loss: 1.1362, Accuracy: 60.17%\n",
            "Batch [1170/1563], Loss: 1.1357, Accuracy: 60.18%\n",
            "Batch [1180/1563], Loss: 1.1361, Accuracy: 60.17%\n",
            "Batch [1190/1563], Loss: 1.1362, Accuracy: 60.17%\n",
            "Batch [1200/1563], Loss: 1.1364, Accuracy: 60.14%\n",
            "Batch [1210/1563], Loss: 1.1357, Accuracy: 60.18%\n",
            "Batch [1220/1563], Loss: 1.1347, Accuracy: 60.23%\n",
            "Batch [1230/1563], Loss: 1.1341, Accuracy: 60.26%\n",
            "Batch [1240/1563], Loss: 1.1325, Accuracy: 60.33%\n",
            "Batch [1250/1563], Loss: 1.1318, Accuracy: 60.36%\n",
            "Batch [1260/1563], Loss: 1.1319, Accuracy: 60.38%\n",
            "Batch [1270/1563], Loss: 1.1309, Accuracy: 60.41%\n",
            "Batch [1280/1563], Loss: 1.1303, Accuracy: 60.44%\n",
            "Batch [1290/1563], Loss: 1.1298, Accuracy: 60.48%\n",
            "Batch [1300/1563], Loss: 1.1296, Accuracy: 60.49%\n",
            "Batch [1310/1563], Loss: 1.1294, Accuracy: 60.47%\n",
            "Batch [1320/1563], Loss: 1.1280, Accuracy: 60.49%\n",
            "Batch [1330/1563], Loss: 1.1278, Accuracy: 60.51%\n",
            "Batch [1340/1563], Loss: 1.1269, Accuracy: 60.53%\n",
            "Batch [1350/1563], Loss: 1.1272, Accuracy: 60.52%\n",
            "Batch [1360/1563], Loss: 1.1267, Accuracy: 60.53%\n",
            "Batch [1370/1563], Loss: 1.1248, Accuracy: 60.59%\n",
            "Batch [1380/1563], Loss: 1.1243, Accuracy: 60.62%\n",
            "Batch [1390/1563], Loss: 1.1237, Accuracy: 60.64%\n",
            "Batch [1400/1563], Loss: 1.1228, Accuracy: 60.66%\n",
            "Batch [1410/1563], Loss: 1.1215, Accuracy: 60.69%\n",
            "Batch [1420/1563], Loss: 1.1213, Accuracy: 60.70%\n",
            "Batch [1430/1563], Loss: 1.1214, Accuracy: 60.71%\n",
            "Batch [1440/1563], Loss: 1.1219, Accuracy: 60.67%\n",
            "Batch [1450/1563], Loss: 1.1216, Accuracy: 60.67%\n",
            "Batch [1460/1563], Loss: 1.1214, Accuracy: 60.67%\n",
            "Batch [1470/1563], Loss: 1.1213, Accuracy: 60.68%\n",
            "Batch [1480/1563], Loss: 1.1206, Accuracy: 60.70%\n",
            "Batch [1490/1563], Loss: 1.1199, Accuracy: 60.72%\n",
            "Batch [1500/1563], Loss: 1.1192, Accuracy: 60.75%\n",
            "Batch [1510/1563], Loss: 1.1184, Accuracy: 60.76%\n",
            "Batch [1520/1563], Loss: 1.1183, Accuracy: 60.80%\n",
            "Batch [1530/1563], Loss: 1.1181, Accuracy: 60.81%\n",
            "Batch [1540/1563], Loss: 1.1178, Accuracy: 60.83%\n",
            "Batch [1550/1563], Loss: 1.1173, Accuracy: 60.86%\n",
            "Batch [1560/1563], Loss: 1.1164, Accuracy: 60.90%\n",
            "Epoch [3/10] - Loss: 1.1163, Accuracy: 60.91%\n",
            "Epoch [4/10]\n",
            "Batch [10/1563], Loss: 1.0371, Accuracy: 63.12%\n",
            "Batch [20/1563], Loss: 0.9999, Accuracy: 65.31%\n",
            "Batch [30/1563], Loss: 0.9886, Accuracy: 66.15%\n",
            "Batch [40/1563], Loss: 0.9675, Accuracy: 66.80%\n",
            "Batch [50/1563], Loss: 0.9835, Accuracy: 65.94%\n",
            "Batch [60/1563], Loss: 0.9912, Accuracy: 65.36%\n",
            "Batch [70/1563], Loss: 0.9964, Accuracy: 65.22%\n",
            "Batch [80/1563], Loss: 1.0051, Accuracy: 64.96%\n",
            "Batch [90/1563], Loss: 1.0102, Accuracy: 64.72%\n",
            "Batch [100/1563], Loss: 1.0128, Accuracy: 64.84%\n",
            "Batch [110/1563], Loss: 1.0165, Accuracy: 64.46%\n",
            "Batch [120/1563], Loss: 1.0207, Accuracy: 64.40%\n",
            "Batch [130/1563], Loss: 1.0164, Accuracy: 64.54%\n",
            "Batch [140/1563], Loss: 1.0208, Accuracy: 64.42%\n",
            "Batch [150/1563], Loss: 1.0147, Accuracy: 64.50%\n",
            "Batch [160/1563], Loss: 1.0098, Accuracy: 64.61%\n",
            "Batch [170/1563], Loss: 1.0084, Accuracy: 64.65%\n",
            "Batch [180/1563], Loss: 1.0119, Accuracy: 64.39%\n",
            "Batch [190/1563], Loss: 1.0102, Accuracy: 64.47%\n",
            "Batch [200/1563], Loss: 1.0058, Accuracy: 64.70%\n",
            "Batch [210/1563], Loss: 0.9997, Accuracy: 64.91%\n",
            "Batch [220/1563], Loss: 0.9967, Accuracy: 64.91%\n",
            "Batch [230/1563], Loss: 0.9963, Accuracy: 64.90%\n",
            "Batch [240/1563], Loss: 0.9963, Accuracy: 64.97%\n",
            "Batch [250/1563], Loss: 0.9951, Accuracy: 65.05%\n",
            "Batch [260/1563], Loss: 0.9938, Accuracy: 65.02%\n",
            "Batch [270/1563], Loss: 0.9892, Accuracy: 65.22%\n",
            "Batch [280/1563], Loss: 0.9930, Accuracy: 65.19%\n",
            "Batch [290/1563], Loss: 0.9952, Accuracy: 64.94%\n",
            "Batch [300/1563], Loss: 0.9901, Accuracy: 65.12%\n",
            "Batch [310/1563], Loss: 0.9855, Accuracy: 65.21%\n",
            "Batch [320/1563], Loss: 0.9859, Accuracy: 65.38%\n",
            "Batch [330/1563], Loss: 0.9884, Accuracy: 65.45%\n",
            "Batch [340/1563], Loss: 0.9876, Accuracy: 65.54%\n",
            "Batch [350/1563], Loss: 0.9884, Accuracy: 65.59%\n",
            "Batch [360/1563], Loss: 0.9886, Accuracy: 65.61%\n",
            "Batch [370/1563], Loss: 0.9885, Accuracy: 65.59%\n",
            "Batch [380/1563], Loss: 0.9901, Accuracy: 65.61%\n",
            "Batch [390/1563], Loss: 0.9898, Accuracy: 65.62%\n",
            "Batch [400/1563], Loss: 0.9892, Accuracy: 65.63%\n",
            "Batch [410/1563], Loss: 0.9906, Accuracy: 65.58%\n",
            "Batch [420/1563], Loss: 0.9923, Accuracy: 65.53%\n",
            "Batch [430/1563], Loss: 0.9926, Accuracy: 65.47%\n",
            "Batch [440/1563], Loss: 0.9905, Accuracy: 65.55%\n",
            "Batch [450/1563], Loss: 0.9915, Accuracy: 65.53%\n",
            "Batch [460/1563], Loss: 0.9899, Accuracy: 65.59%\n",
            "Batch [470/1563], Loss: 0.9897, Accuracy: 65.57%\n",
            "Batch [480/1563], Loss: 0.9879, Accuracy: 65.64%\n",
            "Batch [490/1563], Loss: 0.9866, Accuracy: 65.68%\n",
            "Batch [500/1563], Loss: 0.9858, Accuracy: 65.72%\n",
            "Batch [510/1563], Loss: 0.9869, Accuracy: 65.70%\n",
            "Batch [520/1563], Loss: 0.9879, Accuracy: 65.71%\n",
            "Batch [530/1563], Loss: 0.9900, Accuracy: 65.62%\n",
            "Batch [540/1563], Loss: 0.9895, Accuracy: 65.63%\n",
            "Batch [550/1563], Loss: 0.9872, Accuracy: 65.70%\n",
            "Batch [560/1563], Loss: 0.9848, Accuracy: 65.84%\n",
            "Batch [570/1563], Loss: 0.9834, Accuracy: 65.88%\n",
            "Batch [580/1563], Loss: 0.9830, Accuracy: 65.89%\n",
            "Batch [590/1563], Loss: 0.9826, Accuracy: 65.92%\n",
            "Batch [600/1563], Loss: 0.9814, Accuracy: 65.96%\n",
            "Batch [610/1563], Loss: 0.9821, Accuracy: 65.91%\n",
            "Batch [620/1563], Loss: 0.9813, Accuracy: 65.94%\n",
            "Batch [630/1563], Loss: 0.9803, Accuracy: 65.96%\n",
            "Batch [640/1563], Loss: 0.9775, Accuracy: 66.08%\n",
            "Batch [650/1563], Loss: 0.9774, Accuracy: 66.04%\n",
            "Batch [660/1563], Loss: 0.9773, Accuracy: 66.04%\n",
            "Batch [670/1563], Loss: 0.9767, Accuracy: 66.00%\n",
            "Batch [680/1563], Loss: 0.9763, Accuracy: 66.03%\n",
            "Batch [690/1563], Loss: 0.9755, Accuracy: 66.04%\n",
            "Batch [700/1563], Loss: 0.9736, Accuracy: 66.10%\n",
            "Batch [710/1563], Loss: 0.9743, Accuracy: 66.10%\n",
            "Batch [720/1563], Loss: 0.9743, Accuracy: 66.09%\n",
            "Batch [730/1563], Loss: 0.9737, Accuracy: 66.10%\n",
            "Batch [740/1563], Loss: 0.9738, Accuracy: 66.13%\n",
            "Batch [750/1563], Loss: 0.9723, Accuracy: 66.20%\n",
            "Batch [760/1563], Loss: 0.9725, Accuracy: 66.18%\n",
            "Batch [770/1563], Loss: 0.9725, Accuracy: 66.18%\n",
            "Batch [780/1563], Loss: 0.9731, Accuracy: 66.14%\n",
            "Batch [790/1563], Loss: 0.9717, Accuracy: 66.20%\n",
            "Batch [800/1563], Loss: 0.9709, Accuracy: 66.25%\n",
            "Batch [810/1563], Loss: 0.9713, Accuracy: 66.28%\n",
            "Batch [820/1563], Loss: 0.9719, Accuracy: 66.28%\n",
            "Batch [830/1563], Loss: 0.9717, Accuracy: 66.29%\n",
            "Batch [840/1563], Loss: 0.9718, Accuracy: 66.28%\n",
            "Batch [850/1563], Loss: 0.9714, Accuracy: 66.31%\n",
            "Batch [860/1563], Loss: 0.9714, Accuracy: 66.30%\n",
            "Batch [870/1563], Loss: 0.9720, Accuracy: 66.30%\n",
            "Batch [880/1563], Loss: 0.9708, Accuracy: 66.34%\n",
            "Batch [890/1563], Loss: 0.9695, Accuracy: 66.38%\n",
            "Batch [900/1563], Loss: 0.9700, Accuracy: 66.40%\n",
            "Batch [910/1563], Loss: 0.9699, Accuracy: 66.44%\n",
            "Batch [920/1563], Loss: 0.9691, Accuracy: 66.47%\n",
            "Batch [930/1563], Loss: 0.9696, Accuracy: 66.45%\n",
            "Batch [940/1563], Loss: 0.9689, Accuracy: 66.47%\n",
            "Batch [950/1563], Loss: 0.9692, Accuracy: 66.48%\n",
            "Batch [960/1563], Loss: 0.9698, Accuracy: 66.46%\n",
            "Batch [970/1563], Loss: 0.9705, Accuracy: 66.39%\n",
            "Batch [980/1563], Loss: 0.9702, Accuracy: 66.41%\n",
            "Batch [990/1563], Loss: 0.9701, Accuracy: 66.37%\n",
            "Batch [1000/1563], Loss: 0.9691, Accuracy: 66.42%\n",
            "Batch [1010/1563], Loss: 0.9687, Accuracy: 66.44%\n",
            "Batch [1020/1563], Loss: 0.9685, Accuracy: 66.44%\n",
            "Batch [1030/1563], Loss: 0.9686, Accuracy: 66.42%\n",
            "Batch [1040/1563], Loss: 0.9676, Accuracy: 66.43%\n",
            "Batch [1050/1563], Loss: 0.9668, Accuracy: 66.49%\n",
            "Batch [1060/1563], Loss: 0.9668, Accuracy: 66.49%\n",
            "Batch [1070/1563], Loss: 0.9665, Accuracy: 66.49%\n",
            "Batch [1080/1563], Loss: 0.9671, Accuracy: 66.50%\n",
            "Batch [1090/1563], Loss: 0.9672, Accuracy: 66.48%\n",
            "Batch [1100/1563], Loss: 0.9674, Accuracy: 66.48%\n",
            "Batch [1110/1563], Loss: 0.9687, Accuracy: 66.44%\n",
            "Batch [1120/1563], Loss: 0.9687, Accuracy: 66.43%\n",
            "Batch [1130/1563], Loss: 0.9668, Accuracy: 66.52%\n",
            "Batch [1140/1563], Loss: 0.9675, Accuracy: 66.49%\n",
            "Batch [1150/1563], Loss: 0.9665, Accuracy: 66.56%\n",
            "Batch [1160/1563], Loss: 0.9667, Accuracy: 66.56%\n",
            "Batch [1170/1563], Loss: 0.9663, Accuracy: 66.57%\n",
            "Batch [1180/1563], Loss: 0.9656, Accuracy: 66.58%\n",
            "Batch [1190/1563], Loss: 0.9658, Accuracy: 66.60%\n",
            "Batch [1200/1563], Loss: 0.9658, Accuracy: 66.62%\n",
            "Batch [1210/1563], Loss: 0.9650, Accuracy: 66.66%\n",
            "Batch [1220/1563], Loss: 0.9645, Accuracy: 66.68%\n",
            "Batch [1230/1563], Loss: 0.9640, Accuracy: 66.72%\n",
            "Batch [1240/1563], Loss: 0.9639, Accuracy: 66.73%\n",
            "Batch [1250/1563], Loss: 0.9637, Accuracy: 66.75%\n",
            "Batch [1260/1563], Loss: 0.9633, Accuracy: 66.75%\n",
            "Batch [1270/1563], Loss: 0.9620, Accuracy: 66.78%\n",
            "Batch [1280/1563], Loss: 0.9611, Accuracy: 66.81%\n",
            "Batch [1290/1563], Loss: 0.9605, Accuracy: 66.84%\n",
            "Batch [1300/1563], Loss: 0.9604, Accuracy: 66.86%\n",
            "Batch [1310/1563], Loss: 0.9599, Accuracy: 66.86%\n",
            "Batch [1320/1563], Loss: 0.9591, Accuracy: 66.89%\n",
            "Batch [1330/1563], Loss: 0.9587, Accuracy: 66.90%\n",
            "Batch [1340/1563], Loss: 0.9579, Accuracy: 66.91%\n",
            "Batch [1350/1563], Loss: 0.9579, Accuracy: 66.88%\n",
            "Batch [1360/1563], Loss: 0.9573, Accuracy: 66.92%\n",
            "Batch [1370/1563], Loss: 0.9568, Accuracy: 66.93%\n",
            "Batch [1380/1563], Loss: 0.9567, Accuracy: 66.95%\n",
            "Batch [1390/1563], Loss: 0.9564, Accuracy: 66.97%\n",
            "Batch [1400/1563], Loss: 0.9561, Accuracy: 66.98%\n",
            "Batch [1410/1563], Loss: 0.9568, Accuracy: 66.96%\n",
            "Batch [1420/1563], Loss: 0.9574, Accuracy: 66.91%\n",
            "Batch [1430/1563], Loss: 0.9571, Accuracy: 66.94%\n",
            "Batch [1440/1563], Loss: 0.9559, Accuracy: 66.98%\n",
            "Batch [1450/1563], Loss: 0.9553, Accuracy: 67.00%\n",
            "Batch [1460/1563], Loss: 0.9552, Accuracy: 67.01%\n",
            "Batch [1470/1563], Loss: 0.9548, Accuracy: 67.02%\n",
            "Batch [1480/1563], Loss: 0.9544, Accuracy: 67.02%\n",
            "Batch [1490/1563], Loss: 0.9530, Accuracy: 67.07%\n",
            "Batch [1500/1563], Loss: 0.9536, Accuracy: 67.07%\n",
            "Batch [1510/1563], Loss: 0.9529, Accuracy: 67.08%\n",
            "Batch [1520/1563], Loss: 0.9527, Accuracy: 67.08%\n",
            "Batch [1530/1563], Loss: 0.9522, Accuracy: 67.10%\n",
            "Batch [1540/1563], Loss: 0.9525, Accuracy: 67.10%\n",
            "Batch [1550/1563], Loss: 0.9513, Accuracy: 67.15%\n",
            "Batch [1560/1563], Loss: 0.9508, Accuracy: 67.17%\n",
            "Epoch [4/10] - Loss: 0.9506, Accuracy: 67.18%\n",
            "Epoch [5/10]\n",
            "Batch [10/1563], Loss: 0.8488, Accuracy: 72.50%\n",
            "Batch [20/1563], Loss: 0.8509, Accuracy: 72.19%\n",
            "Batch [30/1563], Loss: 0.8153, Accuracy: 72.19%\n",
            "Batch [40/1563], Loss: 0.8462, Accuracy: 72.03%\n",
            "Batch [50/1563], Loss: 0.8447, Accuracy: 72.50%\n",
            "Batch [60/1563], Loss: 0.8419, Accuracy: 72.08%\n",
            "Batch [70/1563], Loss: 0.8445, Accuracy: 72.01%\n",
            "Batch [80/1563], Loss: 0.8473, Accuracy: 71.41%\n",
            "Batch [90/1563], Loss: 0.8476, Accuracy: 71.22%\n",
            "Batch [100/1563], Loss: 0.8541, Accuracy: 71.00%\n",
            "Batch [110/1563], Loss: 0.8596, Accuracy: 70.80%\n",
            "Batch [120/1563], Loss: 0.8357, Accuracy: 71.59%\n",
            "Batch [130/1563], Loss: 0.8279, Accuracy: 71.68%\n",
            "Batch [140/1563], Loss: 0.8325, Accuracy: 71.67%\n",
            "Batch [150/1563], Loss: 0.8405, Accuracy: 71.19%\n",
            "Batch [160/1563], Loss: 0.8419, Accuracy: 71.11%\n",
            "Batch [170/1563], Loss: 0.8449, Accuracy: 71.08%\n",
            "Batch [180/1563], Loss: 0.8466, Accuracy: 70.97%\n",
            "Batch [190/1563], Loss: 0.8429, Accuracy: 71.10%\n",
            "Batch [200/1563], Loss: 0.8437, Accuracy: 70.92%\n",
            "Batch [210/1563], Loss: 0.8439, Accuracy: 70.94%\n",
            "Batch [220/1563], Loss: 0.8430, Accuracy: 70.80%\n",
            "Batch [230/1563], Loss: 0.8474, Accuracy: 70.82%\n",
            "Batch [240/1563], Loss: 0.8519, Accuracy: 70.57%\n",
            "Batch [250/1563], Loss: 0.8504, Accuracy: 70.70%\n",
            "Batch [260/1563], Loss: 0.8501, Accuracy: 70.69%\n",
            "Batch [270/1563], Loss: 0.8517, Accuracy: 70.64%\n",
            "Batch [280/1563], Loss: 0.8539, Accuracy: 70.51%\n",
            "Batch [290/1563], Loss: 0.8534, Accuracy: 70.58%\n",
            "Batch [300/1563], Loss: 0.8546, Accuracy: 70.55%\n",
            "Batch [310/1563], Loss: 0.8509, Accuracy: 70.65%\n",
            "Batch [320/1563], Loss: 0.8539, Accuracy: 70.49%\n",
            "Batch [330/1563], Loss: 0.8513, Accuracy: 70.51%\n",
            "Batch [340/1563], Loss: 0.8540, Accuracy: 70.41%\n",
            "Batch [350/1563], Loss: 0.8530, Accuracy: 70.44%\n",
            "Batch [360/1563], Loss: 0.8522, Accuracy: 70.49%\n",
            "Batch [370/1563], Loss: 0.8502, Accuracy: 70.57%\n",
            "Batch [380/1563], Loss: 0.8495, Accuracy: 70.54%\n",
            "Batch [390/1563], Loss: 0.8507, Accuracy: 70.51%\n",
            "Batch [400/1563], Loss: 0.8494, Accuracy: 70.58%\n",
            "Batch [410/1563], Loss: 0.8465, Accuracy: 70.67%\n",
            "Batch [420/1563], Loss: 0.8460, Accuracy: 70.71%\n",
            "Batch [430/1563], Loss: 0.8451, Accuracy: 70.69%\n",
            "Batch [440/1563], Loss: 0.8432, Accuracy: 70.77%\n",
            "Batch [450/1563], Loss: 0.8439, Accuracy: 70.76%\n",
            "Batch [460/1563], Loss: 0.8454, Accuracy: 70.74%\n",
            "Batch [470/1563], Loss: 0.8458, Accuracy: 70.72%\n",
            "Batch [480/1563], Loss: 0.8454, Accuracy: 70.75%\n",
            "Batch [490/1563], Loss: 0.8475, Accuracy: 70.66%\n",
            "Batch [500/1563], Loss: 0.8476, Accuracy: 70.60%\n",
            "Batch [510/1563], Loss: 0.8488, Accuracy: 70.59%\n",
            "Batch [520/1563], Loss: 0.8514, Accuracy: 70.50%\n",
            "Batch [530/1563], Loss: 0.8508, Accuracy: 70.51%\n",
            "Batch [540/1563], Loss: 0.8512, Accuracy: 70.49%\n",
            "Batch [550/1563], Loss: 0.8512, Accuracy: 70.44%\n",
            "Batch [560/1563], Loss: 0.8518, Accuracy: 70.39%\n",
            "Batch [570/1563], Loss: 0.8520, Accuracy: 70.39%\n",
            "Batch [580/1563], Loss: 0.8542, Accuracy: 70.36%\n",
            "Batch [590/1563], Loss: 0.8554, Accuracy: 70.32%\n",
            "Batch [600/1563], Loss: 0.8568, Accuracy: 70.30%\n",
            "Batch [610/1563], Loss: 0.8581, Accuracy: 70.29%\n",
            "Batch [620/1563], Loss: 0.8594, Accuracy: 70.23%\n",
            "Batch [630/1563], Loss: 0.8596, Accuracy: 70.24%\n",
            "Batch [640/1563], Loss: 0.8577, Accuracy: 70.28%\n",
            "Batch [650/1563], Loss: 0.8552, Accuracy: 70.41%\n",
            "Batch [660/1563], Loss: 0.8552, Accuracy: 70.38%\n",
            "Batch [670/1563], Loss: 0.8581, Accuracy: 70.32%\n",
            "Batch [680/1563], Loss: 0.8573, Accuracy: 70.30%\n",
            "Batch [690/1563], Loss: 0.8579, Accuracy: 70.26%\n",
            "Batch [700/1563], Loss: 0.8592, Accuracy: 70.24%\n",
            "Batch [710/1563], Loss: 0.8585, Accuracy: 70.29%\n",
            "Batch [720/1563], Loss: 0.8583, Accuracy: 70.35%\n",
            "Batch [730/1563], Loss: 0.8596, Accuracy: 70.31%\n",
            "Batch [740/1563], Loss: 0.8600, Accuracy: 70.33%\n",
            "Batch [750/1563], Loss: 0.8595, Accuracy: 70.31%\n",
            "Batch [760/1563], Loss: 0.8595, Accuracy: 70.34%\n",
            "Batch [770/1563], Loss: 0.8589, Accuracy: 70.37%\n",
            "Batch [780/1563], Loss: 0.8592, Accuracy: 70.35%\n",
            "Batch [790/1563], Loss: 0.8593, Accuracy: 70.36%\n",
            "Batch [800/1563], Loss: 0.8605, Accuracy: 70.33%\n",
            "Batch [810/1563], Loss: 0.8614, Accuracy: 70.30%\n",
            "Batch [820/1563], Loss: 0.8614, Accuracy: 70.30%\n",
            "Batch [830/1563], Loss: 0.8614, Accuracy: 70.30%\n",
            "Batch [840/1563], Loss: 0.8601, Accuracy: 70.34%\n",
            "Batch [850/1563], Loss: 0.8597, Accuracy: 70.36%\n",
            "Batch [860/1563], Loss: 0.8598, Accuracy: 70.37%\n",
            "Batch [870/1563], Loss: 0.8591, Accuracy: 70.38%\n",
            "Batch [880/1563], Loss: 0.8590, Accuracy: 70.39%\n",
            "Batch [890/1563], Loss: 0.8584, Accuracy: 70.38%\n",
            "Batch [900/1563], Loss: 0.8579, Accuracy: 70.38%\n",
            "Batch [910/1563], Loss: 0.8578, Accuracy: 70.39%\n",
            "Batch [920/1563], Loss: 0.8572, Accuracy: 70.43%\n",
            "Batch [930/1563], Loss: 0.8576, Accuracy: 70.41%\n",
            "Batch [940/1563], Loss: 0.8559, Accuracy: 70.49%\n",
            "Batch [950/1563], Loss: 0.8552, Accuracy: 70.51%\n",
            "Batch [960/1563], Loss: 0.8546, Accuracy: 70.50%\n",
            "Batch [970/1563], Loss: 0.8552, Accuracy: 70.49%\n",
            "Batch [980/1563], Loss: 0.8543, Accuracy: 70.55%\n",
            "Batch [990/1563], Loss: 0.8548, Accuracy: 70.52%\n",
            "Batch [1000/1563], Loss: 0.8540, Accuracy: 70.56%\n",
            "Batch [1010/1563], Loss: 0.8543, Accuracy: 70.54%\n",
            "Batch [1020/1563], Loss: 0.8544, Accuracy: 70.52%\n",
            "Batch [1030/1563], Loss: 0.8544, Accuracy: 70.52%\n",
            "Batch [1040/1563], Loss: 0.8542, Accuracy: 70.53%\n",
            "Batch [1050/1563], Loss: 0.8532, Accuracy: 70.58%\n",
            "Batch [1060/1563], Loss: 0.8522, Accuracy: 70.62%\n",
            "Batch [1070/1563], Loss: 0.8529, Accuracy: 70.59%\n",
            "Batch [1080/1563], Loss: 0.8526, Accuracy: 70.59%\n",
            "Batch [1090/1563], Loss: 0.8523, Accuracy: 70.60%\n",
            "Batch [1100/1563], Loss: 0.8522, Accuracy: 70.63%\n",
            "Batch [1110/1563], Loss: 0.8521, Accuracy: 70.62%\n",
            "Batch [1120/1563], Loss: 0.8521, Accuracy: 70.63%\n",
            "Batch [1130/1563], Loss: 0.8507, Accuracy: 70.66%\n",
            "Batch [1140/1563], Loss: 0.8511, Accuracy: 70.66%\n",
            "Batch [1150/1563], Loss: 0.8513, Accuracy: 70.66%\n",
            "Batch [1160/1563], Loss: 0.8510, Accuracy: 70.68%\n",
            "Batch [1170/1563], Loss: 0.8505, Accuracy: 70.69%\n",
            "Batch [1180/1563], Loss: 0.8505, Accuracy: 70.72%\n",
            "Batch [1190/1563], Loss: 0.8514, Accuracy: 70.70%\n",
            "Batch [1200/1563], Loss: 0.8512, Accuracy: 70.69%\n",
            "Batch [1210/1563], Loss: 0.8513, Accuracy: 70.71%\n",
            "Batch [1220/1563], Loss: 0.8516, Accuracy: 70.69%\n",
            "Batch [1230/1563], Loss: 0.8521, Accuracy: 70.66%\n",
            "Batch [1240/1563], Loss: 0.8531, Accuracy: 70.60%\n",
            "Batch [1250/1563], Loss: 0.8521, Accuracy: 70.65%\n",
            "Batch [1260/1563], Loss: 0.8522, Accuracy: 70.63%\n",
            "Batch [1270/1563], Loss: 0.8512, Accuracy: 70.68%\n",
            "Batch [1280/1563], Loss: 0.8508, Accuracy: 70.69%\n",
            "Batch [1290/1563], Loss: 0.8507, Accuracy: 70.68%\n",
            "Batch [1300/1563], Loss: 0.8506, Accuracy: 70.70%\n",
            "Batch [1310/1563], Loss: 0.8503, Accuracy: 70.72%\n",
            "Batch [1320/1563], Loss: 0.8499, Accuracy: 70.73%\n",
            "Batch [1330/1563], Loss: 0.8494, Accuracy: 70.75%\n",
            "Batch [1340/1563], Loss: 0.8498, Accuracy: 70.76%\n",
            "Batch [1350/1563], Loss: 0.8490, Accuracy: 70.78%\n",
            "Batch [1360/1563], Loss: 0.8488, Accuracy: 70.79%\n",
            "Batch [1370/1563], Loss: 0.8492, Accuracy: 70.80%\n",
            "Batch [1380/1563], Loss: 0.8496, Accuracy: 70.77%\n",
            "Batch [1390/1563], Loss: 0.8488, Accuracy: 70.81%\n",
            "Batch [1400/1563], Loss: 0.8487, Accuracy: 70.82%\n",
            "Batch [1410/1563], Loss: 0.8482, Accuracy: 70.82%\n",
            "Batch [1420/1563], Loss: 0.8476, Accuracy: 70.85%\n",
            "Batch [1430/1563], Loss: 0.8473, Accuracy: 70.85%\n",
            "Batch [1440/1563], Loss: 0.8478, Accuracy: 70.82%\n",
            "Batch [1450/1563], Loss: 0.8477, Accuracy: 70.84%\n",
            "Batch [1460/1563], Loss: 0.8470, Accuracy: 70.86%\n",
            "Batch [1470/1563], Loss: 0.8468, Accuracy: 70.87%\n",
            "Batch [1480/1563], Loss: 0.8467, Accuracy: 70.89%\n",
            "Batch [1490/1563], Loss: 0.8466, Accuracy: 70.89%\n",
            "Batch [1500/1563], Loss: 0.8459, Accuracy: 70.92%\n",
            "Batch [1510/1563], Loss: 0.8450, Accuracy: 70.97%\n",
            "Batch [1520/1563], Loss: 0.8450, Accuracy: 70.97%\n",
            "Batch [1530/1563], Loss: 0.8444, Accuracy: 71.01%\n",
            "Batch [1540/1563], Loss: 0.8436, Accuracy: 71.02%\n",
            "Batch [1550/1563], Loss: 0.8440, Accuracy: 71.03%\n",
            "Batch [1560/1563], Loss: 0.8433, Accuracy: 71.05%\n",
            "Epoch [5/10] - Loss: 0.8429, Accuracy: 71.07%\n",
            "Epoch [6/10]\n",
            "Batch [10/1563], Loss: 0.7947, Accuracy: 71.25%\n",
            "Batch [20/1563], Loss: 0.8029, Accuracy: 71.09%\n",
            "Batch [30/1563], Loss: 0.7821, Accuracy: 72.81%\n",
            "Batch [40/1563], Loss: 0.7708, Accuracy: 73.83%\n",
            "Batch [50/1563], Loss: 0.7541, Accuracy: 74.12%\n",
            "Batch [60/1563], Loss: 0.7374, Accuracy: 74.79%\n",
            "Batch [70/1563], Loss: 0.7466, Accuracy: 74.46%\n",
            "Batch [80/1563], Loss: 0.7530, Accuracy: 74.45%\n",
            "Batch [90/1563], Loss: 0.7363, Accuracy: 75.24%\n",
            "Batch [100/1563], Loss: 0.7265, Accuracy: 75.66%\n",
            "Batch [110/1563], Loss: 0.7423, Accuracy: 75.06%\n",
            "Batch [120/1563], Loss: 0.7529, Accuracy: 74.53%\n",
            "Batch [130/1563], Loss: 0.7574, Accuracy: 74.50%\n",
            "Batch [140/1563], Loss: 0.7610, Accuracy: 74.38%\n",
            "Batch [150/1563], Loss: 0.7562, Accuracy: 74.46%\n",
            "Batch [160/1563], Loss: 0.7594, Accuracy: 74.57%\n",
            "Batch [170/1563], Loss: 0.7574, Accuracy: 74.71%\n",
            "Batch [180/1563], Loss: 0.7561, Accuracy: 74.58%\n",
            "Batch [190/1563], Loss: 0.7566, Accuracy: 74.59%\n",
            "Batch [200/1563], Loss: 0.7612, Accuracy: 74.52%\n",
            "Batch [210/1563], Loss: 0.7657, Accuracy: 74.33%\n",
            "Batch [220/1563], Loss: 0.7632, Accuracy: 74.32%\n",
            "Batch [230/1563], Loss: 0.7633, Accuracy: 74.18%\n",
            "Batch [240/1563], Loss: 0.7670, Accuracy: 74.11%\n",
            "Batch [250/1563], Loss: 0.7646, Accuracy: 74.15%\n",
            "Batch [260/1563], Loss: 0.7645, Accuracy: 74.09%\n",
            "Batch [270/1563], Loss: 0.7621, Accuracy: 74.16%\n",
            "Batch [280/1563], Loss: 0.7605, Accuracy: 74.20%\n",
            "Batch [290/1563], Loss: 0.7605, Accuracy: 74.15%\n",
            "Batch [300/1563], Loss: 0.7609, Accuracy: 74.07%\n",
            "Batch [310/1563], Loss: 0.7640, Accuracy: 74.06%\n",
            "Batch [320/1563], Loss: 0.7674, Accuracy: 73.96%\n",
            "Batch [330/1563], Loss: 0.7649, Accuracy: 74.05%\n",
            "Batch [340/1563], Loss: 0.7621, Accuracy: 74.12%\n",
            "Batch [350/1563], Loss: 0.7623, Accuracy: 74.20%\n",
            "Batch [360/1563], Loss: 0.7649, Accuracy: 74.15%\n",
            "Batch [370/1563], Loss: 0.7637, Accuracy: 74.19%\n",
            "Batch [380/1563], Loss: 0.7611, Accuracy: 74.30%\n",
            "Batch [390/1563], Loss: 0.7595, Accuracy: 74.28%\n",
            "Batch [400/1563], Loss: 0.7587, Accuracy: 74.29%\n",
            "Batch [410/1563], Loss: 0.7598, Accuracy: 74.26%\n",
            "Batch [420/1563], Loss: 0.7577, Accuracy: 74.26%\n",
            "Batch [430/1563], Loss: 0.7572, Accuracy: 74.21%\n",
            "Batch [440/1563], Loss: 0.7586, Accuracy: 74.13%\n",
            "Batch [450/1563], Loss: 0.7590, Accuracy: 74.04%\n",
            "Batch [460/1563], Loss: 0.7595, Accuracy: 74.04%\n",
            "Batch [470/1563], Loss: 0.7584, Accuracy: 74.06%\n",
            "Batch [480/1563], Loss: 0.7596, Accuracy: 74.00%\n",
            "Batch [490/1563], Loss: 0.7599, Accuracy: 74.04%\n",
            "Batch [500/1563], Loss: 0.7589, Accuracy: 74.01%\n",
            "Batch [510/1563], Loss: 0.7596, Accuracy: 74.00%\n",
            "Batch [520/1563], Loss: 0.7607, Accuracy: 74.00%\n",
            "Batch [530/1563], Loss: 0.7602, Accuracy: 74.06%\n",
            "Batch [540/1563], Loss: 0.7603, Accuracy: 74.08%\n",
            "Batch [550/1563], Loss: 0.7610, Accuracy: 74.02%\n",
            "Batch [560/1563], Loss: 0.7617, Accuracy: 73.98%\n",
            "Batch [570/1563], Loss: 0.7624, Accuracy: 73.94%\n",
            "Batch [580/1563], Loss: 0.7634, Accuracy: 73.87%\n",
            "Batch [590/1563], Loss: 0.7635, Accuracy: 73.88%\n",
            "Batch [600/1563], Loss: 0.7632, Accuracy: 73.86%\n",
            "Batch [610/1563], Loss: 0.7629, Accuracy: 73.84%\n",
            "Batch [620/1563], Loss: 0.7636, Accuracy: 73.78%\n",
            "Batch [630/1563], Loss: 0.7641, Accuracy: 73.80%\n",
            "Batch [640/1563], Loss: 0.7630, Accuracy: 73.82%\n",
            "Batch [650/1563], Loss: 0.7630, Accuracy: 73.80%\n",
            "Batch [660/1563], Loss: 0.7619, Accuracy: 73.82%\n",
            "Batch [670/1563], Loss: 0.7628, Accuracy: 73.75%\n",
            "Batch [680/1563], Loss: 0.7640, Accuracy: 73.69%\n",
            "Batch [690/1563], Loss: 0.7636, Accuracy: 73.69%\n",
            "Batch [700/1563], Loss: 0.7622, Accuracy: 73.74%\n",
            "Batch [710/1563], Loss: 0.7620, Accuracy: 73.72%\n",
            "Batch [720/1563], Loss: 0.7612, Accuracy: 73.73%\n",
            "Batch [730/1563], Loss: 0.7626, Accuracy: 73.68%\n",
            "Batch [740/1563], Loss: 0.7633, Accuracy: 73.67%\n",
            "Batch [750/1563], Loss: 0.7622, Accuracy: 73.69%\n",
            "Batch [760/1563], Loss: 0.7613, Accuracy: 73.73%\n",
            "Batch [770/1563], Loss: 0.7611, Accuracy: 73.73%\n",
            "Batch [780/1563], Loss: 0.7613, Accuracy: 73.73%\n",
            "Batch [790/1563], Loss: 0.7607, Accuracy: 73.72%\n",
            "Batch [800/1563], Loss: 0.7588, Accuracy: 73.78%\n",
            "Batch [810/1563], Loss: 0.7572, Accuracy: 73.83%\n",
            "Batch [820/1563], Loss: 0.7575, Accuracy: 73.82%\n",
            "Batch [830/1563], Loss: 0.7570, Accuracy: 73.84%\n",
            "Batch [840/1563], Loss: 0.7568, Accuracy: 73.85%\n",
            "Batch [850/1563], Loss: 0.7568, Accuracy: 73.83%\n",
            "Batch [860/1563], Loss: 0.7570, Accuracy: 73.84%\n",
            "Batch [870/1563], Loss: 0.7562, Accuracy: 73.84%\n",
            "Batch [880/1563], Loss: 0.7574, Accuracy: 73.79%\n",
            "Batch [890/1563], Loss: 0.7577, Accuracy: 73.80%\n",
            "Batch [900/1563], Loss: 0.7585, Accuracy: 73.75%\n",
            "Batch [910/1563], Loss: 0.7591, Accuracy: 73.72%\n",
            "Batch [920/1563], Loss: 0.7584, Accuracy: 73.75%\n",
            "Batch [930/1563], Loss: 0.7584, Accuracy: 73.76%\n",
            "Batch [940/1563], Loss: 0.7584, Accuracy: 73.77%\n",
            "Batch [950/1563], Loss: 0.7578, Accuracy: 73.80%\n",
            "Batch [960/1563], Loss: 0.7575, Accuracy: 73.81%\n",
            "Batch [970/1563], Loss: 0.7578, Accuracy: 73.80%\n",
            "Batch [980/1563], Loss: 0.7576, Accuracy: 73.77%\n",
            "Batch [990/1563], Loss: 0.7578, Accuracy: 73.77%\n",
            "Batch [1000/1563], Loss: 0.7585, Accuracy: 73.77%\n",
            "Batch [1010/1563], Loss: 0.7580, Accuracy: 73.78%\n",
            "Batch [1020/1563], Loss: 0.7582, Accuracy: 73.78%\n",
            "Batch [1030/1563], Loss: 0.7578, Accuracy: 73.81%\n",
            "Batch [1040/1563], Loss: 0.7578, Accuracy: 73.83%\n",
            "Batch [1050/1563], Loss: 0.7575, Accuracy: 73.83%\n",
            "Batch [1060/1563], Loss: 0.7572, Accuracy: 73.83%\n",
            "Batch [1070/1563], Loss: 0.7580, Accuracy: 73.79%\n",
            "Batch [1080/1563], Loss: 0.7580, Accuracy: 73.79%\n",
            "Batch [1090/1563], Loss: 0.7579, Accuracy: 73.81%\n",
            "Batch [1100/1563], Loss: 0.7584, Accuracy: 73.79%\n",
            "Batch [1110/1563], Loss: 0.7584, Accuracy: 73.80%\n",
            "Batch [1120/1563], Loss: 0.7583, Accuracy: 73.81%\n",
            "Batch [1130/1563], Loss: 0.7570, Accuracy: 73.85%\n",
            "Batch [1140/1563], Loss: 0.7566, Accuracy: 73.86%\n",
            "Batch [1150/1563], Loss: 0.7559, Accuracy: 73.89%\n",
            "Batch [1160/1563], Loss: 0.7552, Accuracy: 73.93%\n",
            "Batch [1170/1563], Loss: 0.7566, Accuracy: 73.92%\n",
            "Batch [1180/1563], Loss: 0.7574, Accuracy: 73.88%\n",
            "Batch [1190/1563], Loss: 0.7586, Accuracy: 73.85%\n",
            "Batch [1200/1563], Loss: 0.7594, Accuracy: 73.84%\n",
            "Batch [1210/1563], Loss: 0.7594, Accuracy: 73.86%\n",
            "Batch [1220/1563], Loss: 0.7596, Accuracy: 73.84%\n",
            "Batch [1230/1563], Loss: 0.7591, Accuracy: 73.85%\n",
            "Batch [1240/1563], Loss: 0.7594, Accuracy: 73.85%\n",
            "Batch [1250/1563], Loss: 0.7592, Accuracy: 73.86%\n",
            "Batch [1260/1563], Loss: 0.7587, Accuracy: 73.90%\n",
            "Batch [1270/1563], Loss: 0.7587, Accuracy: 73.91%\n",
            "Batch [1280/1563], Loss: 0.7584, Accuracy: 73.93%\n",
            "Batch [1290/1563], Loss: 0.7596, Accuracy: 73.91%\n",
            "Batch [1300/1563], Loss: 0.7595, Accuracy: 73.90%\n",
            "Batch [1310/1563], Loss: 0.7604, Accuracy: 73.88%\n",
            "Batch [1320/1563], Loss: 0.7594, Accuracy: 73.91%\n",
            "Batch [1330/1563], Loss: 0.7593, Accuracy: 73.90%\n",
            "Batch [1340/1563], Loss: 0.7594, Accuracy: 73.89%\n",
            "Batch [1350/1563], Loss: 0.7596, Accuracy: 73.89%\n",
            "Batch [1360/1563], Loss: 0.7597, Accuracy: 73.89%\n",
            "Batch [1370/1563], Loss: 0.7603, Accuracy: 73.88%\n",
            "Batch [1380/1563], Loss: 0.7606, Accuracy: 73.88%\n",
            "Batch [1390/1563], Loss: 0.7609, Accuracy: 73.89%\n",
            "Batch [1400/1563], Loss: 0.7611, Accuracy: 73.90%\n",
            "Batch [1410/1563], Loss: 0.7618, Accuracy: 73.90%\n",
            "Batch [1420/1563], Loss: 0.7607, Accuracy: 73.93%\n",
            "Batch [1430/1563], Loss: 0.7607, Accuracy: 73.94%\n",
            "Batch [1440/1563], Loss: 0.7612, Accuracy: 73.92%\n",
            "Batch [1450/1563], Loss: 0.7612, Accuracy: 73.93%\n",
            "Batch [1460/1563], Loss: 0.7606, Accuracy: 73.94%\n",
            "Batch [1470/1563], Loss: 0.7602, Accuracy: 73.95%\n",
            "Batch [1480/1563], Loss: 0.7606, Accuracy: 73.93%\n",
            "Batch [1490/1563], Loss: 0.7607, Accuracy: 73.93%\n",
            "Batch [1500/1563], Loss: 0.7604, Accuracy: 73.94%\n",
            "Batch [1510/1563], Loss: 0.7602, Accuracy: 73.94%\n",
            "Batch [1520/1563], Loss: 0.7605, Accuracy: 73.93%\n",
            "Batch [1530/1563], Loss: 0.7603, Accuracy: 73.94%\n",
            "Batch [1540/1563], Loss: 0.7601, Accuracy: 73.94%\n",
            "Batch [1550/1563], Loss: 0.7596, Accuracy: 73.95%\n",
            "Batch [1560/1563], Loss: 0.7589, Accuracy: 73.97%\n",
            "Epoch [6/10] - Loss: 0.7588, Accuracy: 73.96%\n",
            "Epoch [7/10]\n",
            "Batch [10/1563], Loss: 0.6307, Accuracy: 80.31%\n",
            "Batch [20/1563], Loss: 0.6049, Accuracy: 80.31%\n",
            "Batch [30/1563], Loss: 0.6727, Accuracy: 77.71%\n",
            "Batch [40/1563], Loss: 0.6788, Accuracy: 77.50%\n",
            "Batch [50/1563], Loss: 0.6723, Accuracy: 77.69%\n",
            "Batch [60/1563], Loss: 0.6705, Accuracy: 77.66%\n",
            "Batch [70/1563], Loss: 0.6564, Accuracy: 78.26%\n",
            "Batch [80/1563], Loss: 0.6540, Accuracy: 78.32%\n",
            "Batch [90/1563], Loss: 0.6584, Accuracy: 78.06%\n",
            "Batch [100/1563], Loss: 0.6763, Accuracy: 77.69%\n",
            "Batch [110/1563], Loss: 0.6878, Accuracy: 77.24%\n",
            "Batch [120/1563], Loss: 0.6881, Accuracy: 77.37%\n",
            "Batch [130/1563], Loss: 0.6859, Accuracy: 77.16%\n",
            "Batch [140/1563], Loss: 0.6852, Accuracy: 77.01%\n",
            "Batch [150/1563], Loss: 0.6863, Accuracy: 77.08%\n",
            "Batch [160/1563], Loss: 0.6888, Accuracy: 76.93%\n",
            "Batch [170/1563], Loss: 0.6843, Accuracy: 76.91%\n",
            "Batch [180/1563], Loss: 0.6830, Accuracy: 76.88%\n",
            "Batch [190/1563], Loss: 0.6829, Accuracy: 76.89%\n",
            "Batch [200/1563], Loss: 0.6795, Accuracy: 76.97%\n",
            "Batch [210/1563], Loss: 0.6835, Accuracy: 76.90%\n",
            "Batch [220/1563], Loss: 0.6841, Accuracy: 76.79%\n",
            "Batch [230/1563], Loss: 0.6827, Accuracy: 76.86%\n",
            "Batch [240/1563], Loss: 0.6847, Accuracy: 76.84%\n",
            "Batch [250/1563], Loss: 0.6833, Accuracy: 76.89%\n",
            "Batch [260/1563], Loss: 0.6827, Accuracy: 76.83%\n",
            "Batch [270/1563], Loss: 0.6832, Accuracy: 76.77%\n",
            "Batch [280/1563], Loss: 0.6825, Accuracy: 76.71%\n",
            "Batch [290/1563], Loss: 0.6801, Accuracy: 76.81%\n",
            "Batch [300/1563], Loss: 0.6793, Accuracy: 76.82%\n",
            "Batch [310/1563], Loss: 0.6806, Accuracy: 76.76%\n",
            "Batch [320/1563], Loss: 0.6796, Accuracy: 76.88%\n",
            "Batch [330/1563], Loss: 0.6809, Accuracy: 76.75%\n",
            "Batch [340/1563], Loss: 0.6801, Accuracy: 76.80%\n",
            "Batch [350/1563], Loss: 0.6781, Accuracy: 76.88%\n",
            "Batch [360/1563], Loss: 0.6791, Accuracy: 76.87%\n",
            "Batch [370/1563], Loss: 0.6783, Accuracy: 76.82%\n",
            "Batch [380/1563], Loss: 0.6813, Accuracy: 76.72%\n",
            "Batch [390/1563], Loss: 0.6830, Accuracy: 76.63%\n",
            "Batch [400/1563], Loss: 0.6818, Accuracy: 76.66%\n",
            "Batch [410/1563], Loss: 0.6817, Accuracy: 76.65%\n",
            "Batch [420/1563], Loss: 0.6805, Accuracy: 76.71%\n",
            "Batch [430/1563], Loss: 0.6803, Accuracy: 76.68%\n",
            "Batch [440/1563], Loss: 0.6802, Accuracy: 76.68%\n",
            "Batch [450/1563], Loss: 0.6814, Accuracy: 76.65%\n",
            "Batch [460/1563], Loss: 0.6823, Accuracy: 76.63%\n",
            "Batch [470/1563], Loss: 0.6840, Accuracy: 76.55%\n",
            "Batch [480/1563], Loss: 0.6841, Accuracy: 76.55%\n",
            "Batch [490/1563], Loss: 0.6845, Accuracy: 76.57%\n",
            "Batch [500/1563], Loss: 0.6848, Accuracy: 76.55%\n",
            "Batch [510/1563], Loss: 0.6834, Accuracy: 76.60%\n",
            "Batch [520/1563], Loss: 0.6840, Accuracy: 76.60%\n",
            "Batch [530/1563], Loss: 0.6848, Accuracy: 76.62%\n",
            "Batch [540/1563], Loss: 0.6849, Accuracy: 76.62%\n",
            "Batch [550/1563], Loss: 0.6854, Accuracy: 76.64%\n",
            "Batch [560/1563], Loss: 0.6849, Accuracy: 76.66%\n",
            "Batch [570/1563], Loss: 0.6867, Accuracy: 76.60%\n",
            "Batch [580/1563], Loss: 0.6869, Accuracy: 76.62%\n",
            "Batch [590/1563], Loss: 0.6873, Accuracy: 76.58%\n",
            "Batch [600/1563], Loss: 0.6878, Accuracy: 76.58%\n",
            "Batch [610/1563], Loss: 0.6865, Accuracy: 76.59%\n",
            "Batch [620/1563], Loss: 0.6873, Accuracy: 76.57%\n",
            "Batch [630/1563], Loss: 0.6874, Accuracy: 76.54%\n",
            "Batch [640/1563], Loss: 0.6876, Accuracy: 76.51%\n",
            "Batch [650/1563], Loss: 0.6867, Accuracy: 76.56%\n",
            "Batch [660/1563], Loss: 0.6879, Accuracy: 76.52%\n",
            "Batch [670/1563], Loss: 0.6879, Accuracy: 76.56%\n",
            "Batch [680/1563], Loss: 0.6870, Accuracy: 76.57%\n",
            "Batch [690/1563], Loss: 0.6867, Accuracy: 76.62%\n",
            "Batch [700/1563], Loss: 0.6853, Accuracy: 76.68%\n",
            "Batch [710/1563], Loss: 0.6858, Accuracy: 76.66%\n",
            "Batch [720/1563], Loss: 0.6855, Accuracy: 76.65%\n",
            "Batch [730/1563], Loss: 0.6842, Accuracy: 76.70%\n",
            "Batch [740/1563], Loss: 0.6842, Accuracy: 76.69%\n",
            "Batch [750/1563], Loss: 0.6835, Accuracy: 76.73%\n",
            "Batch [760/1563], Loss: 0.6853, Accuracy: 76.67%\n",
            "Batch [770/1563], Loss: 0.6853, Accuracy: 76.67%\n",
            "Batch [780/1563], Loss: 0.6855, Accuracy: 76.64%\n",
            "Batch [790/1563], Loss: 0.6847, Accuracy: 76.64%\n",
            "Batch [800/1563], Loss: 0.6849, Accuracy: 76.63%\n",
            "Batch [810/1563], Loss: 0.6839, Accuracy: 76.66%\n",
            "Batch [820/1563], Loss: 0.6830, Accuracy: 76.69%\n",
            "Batch [830/1563], Loss: 0.6840, Accuracy: 76.68%\n",
            "Batch [840/1563], Loss: 0.6831, Accuracy: 76.72%\n",
            "Batch [850/1563], Loss: 0.6818, Accuracy: 76.74%\n",
            "Batch [860/1563], Loss: 0.6815, Accuracy: 76.74%\n",
            "Batch [870/1563], Loss: 0.6807, Accuracy: 76.76%\n",
            "Batch [880/1563], Loss: 0.6793, Accuracy: 76.83%\n",
            "Batch [890/1563], Loss: 0.6809, Accuracy: 76.77%\n",
            "Batch [900/1563], Loss: 0.6810, Accuracy: 76.77%\n",
            "Batch [910/1563], Loss: 0.6812, Accuracy: 76.74%\n",
            "Batch [920/1563], Loss: 0.6812, Accuracy: 76.76%\n",
            "Batch [930/1563], Loss: 0.6811, Accuracy: 76.76%\n",
            "Batch [940/1563], Loss: 0.6805, Accuracy: 76.77%\n",
            "Batch [950/1563], Loss: 0.6803, Accuracy: 76.78%\n",
            "Batch [960/1563], Loss: 0.6800, Accuracy: 76.81%\n",
            "Batch [970/1563], Loss: 0.6793, Accuracy: 76.84%\n",
            "Batch [980/1563], Loss: 0.6803, Accuracy: 76.78%\n",
            "Batch [990/1563], Loss: 0.6808, Accuracy: 76.76%\n",
            "Batch [1000/1563], Loss: 0.6808, Accuracy: 76.77%\n",
            "Batch [1010/1563], Loss: 0.6814, Accuracy: 76.76%\n",
            "Batch [1020/1563], Loss: 0.6806, Accuracy: 76.79%\n",
            "Batch [1030/1563], Loss: 0.6800, Accuracy: 76.82%\n",
            "Batch [1040/1563], Loss: 0.6810, Accuracy: 76.78%\n",
            "Batch [1050/1563], Loss: 0.6824, Accuracy: 76.74%\n",
            "Batch [1060/1563], Loss: 0.6827, Accuracy: 76.73%\n",
            "Batch [1070/1563], Loss: 0.6834, Accuracy: 76.72%\n",
            "Batch [1080/1563], Loss: 0.6834, Accuracy: 76.71%\n",
            "Batch [1090/1563], Loss: 0.6836, Accuracy: 76.69%\n",
            "Batch [1100/1563], Loss: 0.6838, Accuracy: 76.70%\n",
            "Batch [1110/1563], Loss: 0.6837, Accuracy: 76.69%\n",
            "Batch [1120/1563], Loss: 0.6841, Accuracy: 76.68%\n",
            "Batch [1130/1563], Loss: 0.6841, Accuracy: 76.66%\n",
            "Batch [1140/1563], Loss: 0.6844, Accuracy: 76.64%\n",
            "Batch [1150/1563], Loss: 0.6840, Accuracy: 76.65%\n",
            "Batch [1160/1563], Loss: 0.6837, Accuracy: 76.66%\n",
            "Batch [1170/1563], Loss: 0.6830, Accuracy: 76.68%\n",
            "Batch [1180/1563], Loss: 0.6837, Accuracy: 76.67%\n",
            "Batch [1190/1563], Loss: 0.6842, Accuracy: 76.65%\n",
            "Batch [1200/1563], Loss: 0.6841, Accuracy: 76.66%\n",
            "Batch [1210/1563], Loss: 0.6842, Accuracy: 76.63%\n",
            "Batch [1220/1563], Loss: 0.6842, Accuracy: 76.62%\n",
            "Batch [1230/1563], Loss: 0.6844, Accuracy: 76.62%\n",
            "Batch [1240/1563], Loss: 0.6840, Accuracy: 76.64%\n",
            "Batch [1250/1563], Loss: 0.6833, Accuracy: 76.67%\n",
            "Batch [1260/1563], Loss: 0.6832, Accuracy: 76.66%\n",
            "Batch [1270/1563], Loss: 0.6827, Accuracy: 76.68%\n",
            "Batch [1280/1563], Loss: 0.6821, Accuracy: 76.70%\n",
            "Batch [1290/1563], Loss: 0.6822, Accuracy: 76.69%\n",
            "Batch [1300/1563], Loss: 0.6818, Accuracy: 76.71%\n",
            "Batch [1310/1563], Loss: 0.6819, Accuracy: 76.71%\n",
            "Batch [1320/1563], Loss: 0.6815, Accuracy: 76.72%\n",
            "Batch [1330/1563], Loss: 0.6807, Accuracy: 76.75%\n",
            "Batch [1340/1563], Loss: 0.6806, Accuracy: 76.75%\n",
            "Batch [1350/1563], Loss: 0.6808, Accuracy: 76.75%\n",
            "Batch [1360/1563], Loss: 0.6806, Accuracy: 76.75%\n",
            "Batch [1370/1563], Loss: 0.6807, Accuracy: 76.74%\n",
            "Batch [1380/1563], Loss: 0.6805, Accuracy: 76.75%\n",
            "Batch [1390/1563], Loss: 0.6807, Accuracy: 76.74%\n",
            "Batch [1400/1563], Loss: 0.6811, Accuracy: 76.71%\n",
            "Batch [1410/1563], Loss: 0.6811, Accuracy: 76.72%\n",
            "Batch [1420/1563], Loss: 0.6811, Accuracy: 76.73%\n",
            "Batch [1430/1563], Loss: 0.6811, Accuracy: 76.72%\n",
            "Batch [1440/1563], Loss: 0.6812, Accuracy: 76.74%\n",
            "Batch [1450/1563], Loss: 0.6809, Accuracy: 76.76%\n",
            "Batch [1460/1563], Loss: 0.6808, Accuracy: 76.74%\n",
            "Batch [1470/1563], Loss: 0.6806, Accuracy: 76.75%\n",
            "Batch [1480/1563], Loss: 0.6803, Accuracy: 76.76%\n",
            "Batch [1490/1563], Loss: 0.6805, Accuracy: 76.76%\n",
            "Batch [1500/1563], Loss: 0.6805, Accuracy: 76.77%\n",
            "Batch [1510/1563], Loss: 0.6807, Accuracy: 76.77%\n",
            "Batch [1520/1563], Loss: 0.6806, Accuracy: 76.78%\n",
            "Batch [1530/1563], Loss: 0.6806, Accuracy: 76.77%\n",
            "Batch [1540/1563], Loss: 0.6801, Accuracy: 76.79%\n",
            "Batch [1550/1563], Loss: 0.6800, Accuracy: 76.81%\n",
            "Batch [1560/1563], Loss: 0.6793, Accuracy: 76.82%\n",
            "Epoch [7/10] - Loss: 0.6792, Accuracy: 76.82%\n",
            "Epoch [8/10]\n",
            "Batch [10/1563], Loss: 0.5708, Accuracy: 80.94%\n",
            "Batch [20/1563], Loss: 0.5799, Accuracy: 80.78%\n",
            "Batch [30/1563], Loss: 0.5707, Accuracy: 81.15%\n",
            "Batch [40/1563], Loss: 0.5693, Accuracy: 81.17%\n",
            "Batch [50/1563], Loss: 0.5701, Accuracy: 81.00%\n",
            "Batch [60/1563], Loss: 0.5775, Accuracy: 80.62%\n",
            "Batch [70/1563], Loss: 0.5855, Accuracy: 80.54%\n",
            "Batch [80/1563], Loss: 0.5969, Accuracy: 79.92%\n",
            "Batch [90/1563], Loss: 0.6047, Accuracy: 79.58%\n",
            "Batch [100/1563], Loss: 0.6078, Accuracy: 79.41%\n",
            "Batch [110/1563], Loss: 0.6098, Accuracy: 79.26%\n",
            "Batch [120/1563], Loss: 0.6102, Accuracy: 79.19%\n",
            "Batch [130/1563], Loss: 0.6138, Accuracy: 79.11%\n",
            "Batch [140/1563], Loss: 0.6132, Accuracy: 79.02%\n",
            "Batch [150/1563], Loss: 0.6142, Accuracy: 78.98%\n",
            "Batch [160/1563], Loss: 0.6148, Accuracy: 78.75%\n",
            "Batch [170/1563], Loss: 0.6151, Accuracy: 78.73%\n",
            "Batch [180/1563], Loss: 0.6137, Accuracy: 78.80%\n",
            "Batch [190/1563], Loss: 0.6113, Accuracy: 78.88%\n",
            "Batch [200/1563], Loss: 0.6136, Accuracy: 78.78%\n",
            "Batch [210/1563], Loss: 0.6148, Accuracy: 78.65%\n",
            "Batch [220/1563], Loss: 0.6188, Accuracy: 78.52%\n",
            "Batch [230/1563], Loss: 0.6217, Accuracy: 78.46%\n",
            "Batch [240/1563], Loss: 0.6221, Accuracy: 78.42%\n",
            "Batch [250/1563], Loss: 0.6216, Accuracy: 78.44%\n",
            "Batch [260/1563], Loss: 0.6185, Accuracy: 78.53%\n",
            "Batch [270/1563], Loss: 0.6184, Accuracy: 78.52%\n",
            "Batch [280/1563], Loss: 0.6177, Accuracy: 78.57%\n",
            "Batch [290/1563], Loss: 0.6167, Accuracy: 78.62%\n",
            "Batch [300/1563], Loss: 0.6163, Accuracy: 78.62%\n",
            "Batch [310/1563], Loss: 0.6190, Accuracy: 78.54%\n",
            "Batch [320/1563], Loss: 0.6183, Accuracy: 78.54%\n",
            "Batch [330/1563], Loss: 0.6177, Accuracy: 78.57%\n",
            "Batch [340/1563], Loss: 0.6180, Accuracy: 78.54%\n",
            "Batch [350/1563], Loss: 0.6166, Accuracy: 78.60%\n",
            "Batch [360/1563], Loss: 0.6179, Accuracy: 78.55%\n",
            "Batch [370/1563], Loss: 0.6166, Accuracy: 78.59%\n",
            "Batch [380/1563], Loss: 0.6173, Accuracy: 78.63%\n",
            "Batch [390/1563], Loss: 0.6156, Accuracy: 78.71%\n",
            "Batch [400/1563], Loss: 0.6146, Accuracy: 78.73%\n",
            "Batch [410/1563], Loss: 0.6157, Accuracy: 78.63%\n",
            "Batch [420/1563], Loss: 0.6148, Accuracy: 78.70%\n",
            "Batch [430/1563], Loss: 0.6117, Accuracy: 78.83%\n",
            "Batch [440/1563], Loss: 0.6099, Accuracy: 78.84%\n",
            "Batch [450/1563], Loss: 0.6082, Accuracy: 78.93%\n",
            "Batch [460/1563], Loss: 0.6084, Accuracy: 78.91%\n",
            "Batch [470/1563], Loss: 0.6086, Accuracy: 78.93%\n",
            "Batch [480/1563], Loss: 0.6093, Accuracy: 78.83%\n",
            "Batch [490/1563], Loss: 0.6098, Accuracy: 78.86%\n",
            "Batch [500/1563], Loss: 0.6093, Accuracy: 78.91%\n",
            "Batch [510/1563], Loss: 0.6110, Accuracy: 78.82%\n",
            "Batch [520/1563], Loss: 0.6097, Accuracy: 78.85%\n",
            "Batch [530/1563], Loss: 0.6103, Accuracy: 78.80%\n",
            "Batch [540/1563], Loss: 0.6116, Accuracy: 78.76%\n",
            "Batch [550/1563], Loss: 0.6106, Accuracy: 78.79%\n",
            "Batch [560/1563], Loss: 0.6109, Accuracy: 78.80%\n",
            "Batch [570/1563], Loss: 0.6100, Accuracy: 78.82%\n",
            "Batch [580/1563], Loss: 0.6101, Accuracy: 78.84%\n",
            "Batch [590/1563], Loss: 0.6110, Accuracy: 78.79%\n",
            "Batch [600/1563], Loss: 0.6107, Accuracy: 78.81%\n",
            "Batch [610/1563], Loss: 0.6117, Accuracy: 78.78%\n",
            "Batch [620/1563], Loss: 0.6107, Accuracy: 78.81%\n",
            "Batch [630/1563], Loss: 0.6108, Accuracy: 78.82%\n",
            "Batch [640/1563], Loss: 0.6117, Accuracy: 78.76%\n",
            "Batch [650/1563], Loss: 0.6127, Accuracy: 78.76%\n",
            "Batch [660/1563], Loss: 0.6146, Accuracy: 78.68%\n",
            "Batch [670/1563], Loss: 0.6155, Accuracy: 78.66%\n",
            "Batch [680/1563], Loss: 0.6158, Accuracy: 78.65%\n",
            "Batch [690/1563], Loss: 0.6154, Accuracy: 78.65%\n",
            "Batch [700/1563], Loss: 0.6155, Accuracy: 78.62%\n",
            "Batch [710/1563], Loss: 0.6151, Accuracy: 78.63%\n",
            "Batch [720/1563], Loss: 0.6156, Accuracy: 78.63%\n",
            "Batch [730/1563], Loss: 0.6152, Accuracy: 78.64%\n",
            "Batch [740/1563], Loss: 0.6149, Accuracy: 78.67%\n",
            "Batch [750/1563], Loss: 0.6157, Accuracy: 78.67%\n",
            "Batch [760/1563], Loss: 0.6170, Accuracy: 78.61%\n",
            "Batch [770/1563], Loss: 0.6173, Accuracy: 78.57%\n",
            "Batch [780/1563], Loss: 0.6178, Accuracy: 78.57%\n",
            "Batch [790/1563], Loss: 0.6160, Accuracy: 78.63%\n",
            "Batch [800/1563], Loss: 0.6159, Accuracy: 78.64%\n",
            "Batch [810/1563], Loss: 0.6153, Accuracy: 78.68%\n",
            "Batch [820/1563], Loss: 0.6143, Accuracy: 78.70%\n",
            "Batch [830/1563], Loss: 0.6152, Accuracy: 78.69%\n",
            "Batch [840/1563], Loss: 0.6165, Accuracy: 78.65%\n",
            "Batch [850/1563], Loss: 0.6158, Accuracy: 78.66%\n",
            "Batch [860/1563], Loss: 0.6155, Accuracy: 78.67%\n",
            "Batch [870/1563], Loss: 0.6157, Accuracy: 78.66%\n",
            "Batch [880/1563], Loss: 0.6164, Accuracy: 78.67%\n",
            "Batch [890/1563], Loss: 0.6168, Accuracy: 78.64%\n",
            "Batch [900/1563], Loss: 0.6181, Accuracy: 78.62%\n",
            "Batch [910/1563], Loss: 0.6174, Accuracy: 78.67%\n",
            "Batch [920/1563], Loss: 0.6175, Accuracy: 78.64%\n",
            "Batch [930/1563], Loss: 0.6173, Accuracy: 78.64%\n",
            "Batch [940/1563], Loss: 0.6179, Accuracy: 78.63%\n",
            "Batch [950/1563], Loss: 0.6180, Accuracy: 78.62%\n",
            "Batch [960/1563], Loss: 0.6174, Accuracy: 78.66%\n",
            "Batch [970/1563], Loss: 0.6173, Accuracy: 78.66%\n",
            "Batch [980/1563], Loss: 0.6175, Accuracy: 78.66%\n",
            "Batch [990/1563], Loss: 0.6166, Accuracy: 78.68%\n",
            "Batch [1000/1563], Loss: 0.6167, Accuracy: 78.69%\n",
            "Batch [1010/1563], Loss: 0.6168, Accuracy: 78.71%\n",
            "Batch [1020/1563], Loss: 0.6171, Accuracy: 78.71%\n",
            "Batch [1030/1563], Loss: 0.6176, Accuracy: 78.68%\n",
            "Batch [1040/1563], Loss: 0.6182, Accuracy: 78.66%\n",
            "Batch [1050/1563], Loss: 0.6178, Accuracy: 78.65%\n",
            "Batch [1060/1563], Loss: 0.6180, Accuracy: 78.65%\n",
            "Batch [1070/1563], Loss: 0.6182, Accuracy: 78.67%\n",
            "Batch [1080/1563], Loss: 0.6174, Accuracy: 78.71%\n",
            "Batch [1090/1563], Loss: 0.6174, Accuracy: 78.72%\n",
            "Batch [1100/1563], Loss: 0.6180, Accuracy: 78.68%\n",
            "Batch [1110/1563], Loss: 0.6179, Accuracy: 78.69%\n",
            "Batch [1120/1563], Loss: 0.6178, Accuracy: 78.69%\n",
            "Batch [1130/1563], Loss: 0.6185, Accuracy: 78.66%\n",
            "Batch [1140/1563], Loss: 0.6190, Accuracy: 78.65%\n",
            "Batch [1150/1563], Loss: 0.6185, Accuracy: 78.68%\n",
            "Batch [1160/1563], Loss: 0.6175, Accuracy: 78.70%\n",
            "Batch [1170/1563], Loss: 0.6169, Accuracy: 78.74%\n",
            "Batch [1180/1563], Loss: 0.6171, Accuracy: 78.73%\n",
            "Batch [1190/1563], Loss: 0.6166, Accuracy: 78.75%\n",
            "Batch [1200/1563], Loss: 0.6167, Accuracy: 78.76%\n",
            "Batch [1210/1563], Loss: 0.6167, Accuracy: 78.76%\n",
            "Batch [1220/1563], Loss: 0.6166, Accuracy: 78.77%\n",
            "Batch [1230/1563], Loss: 0.6165, Accuracy: 78.78%\n",
            "Batch [1240/1563], Loss: 0.6162, Accuracy: 78.78%\n",
            "Batch [1250/1563], Loss: 0.6159, Accuracy: 78.78%\n",
            "Batch [1260/1563], Loss: 0.6160, Accuracy: 78.77%\n",
            "Batch [1270/1563], Loss: 0.6156, Accuracy: 78.78%\n",
            "Batch [1280/1563], Loss: 0.6158, Accuracy: 78.75%\n",
            "Batch [1290/1563], Loss: 0.6168, Accuracy: 78.73%\n",
            "Batch [1300/1563], Loss: 0.6169, Accuracy: 78.72%\n",
            "Batch [1310/1563], Loss: 0.6161, Accuracy: 78.75%\n",
            "Batch [1320/1563], Loss: 0.6155, Accuracy: 78.79%\n",
            "Batch [1330/1563], Loss: 0.6166, Accuracy: 78.76%\n",
            "Batch [1340/1563], Loss: 0.6175, Accuracy: 78.73%\n",
            "Batch [1350/1563], Loss: 0.6181, Accuracy: 78.71%\n",
            "Batch [1360/1563], Loss: 0.6184, Accuracy: 78.71%\n",
            "Batch [1370/1563], Loss: 0.6184, Accuracy: 78.72%\n",
            "Batch [1380/1563], Loss: 0.6183, Accuracy: 78.74%\n",
            "Batch [1390/1563], Loss: 0.6184, Accuracy: 78.73%\n",
            "Batch [1400/1563], Loss: 0.6190, Accuracy: 78.71%\n",
            "Batch [1410/1563], Loss: 0.6200, Accuracy: 78.67%\n",
            "Batch [1420/1563], Loss: 0.6201, Accuracy: 78.68%\n",
            "Batch [1430/1563], Loss: 0.6199, Accuracy: 78.70%\n",
            "Batch [1440/1563], Loss: 0.6196, Accuracy: 78.71%\n",
            "Batch [1450/1563], Loss: 0.6197, Accuracy: 78.73%\n",
            "Batch [1460/1563], Loss: 0.6200, Accuracy: 78.72%\n",
            "Batch [1470/1563], Loss: 0.6198, Accuracy: 78.70%\n",
            "Batch [1480/1563], Loss: 0.6202, Accuracy: 78.68%\n",
            "Batch [1490/1563], Loss: 0.6198, Accuracy: 78.69%\n",
            "Batch [1500/1563], Loss: 0.6197, Accuracy: 78.70%\n",
            "Batch [1510/1563], Loss: 0.6195, Accuracy: 78.72%\n",
            "Batch [1520/1563], Loss: 0.6199, Accuracy: 78.72%\n",
            "Batch [1530/1563], Loss: 0.6193, Accuracy: 78.74%\n",
            "Batch [1540/1563], Loss: 0.6187, Accuracy: 78.75%\n",
            "Batch [1550/1563], Loss: 0.6181, Accuracy: 78.77%\n",
            "Batch [1560/1563], Loss: 0.6186, Accuracy: 78.76%\n",
            "Epoch [8/10] - Loss: 0.6186, Accuracy: 78.77%\n",
            "Epoch [9/10]\n",
            "Batch [10/1563], Loss: 0.5551, Accuracy: 80.94%\n",
            "Batch [20/1563], Loss: 0.5630, Accuracy: 80.78%\n",
            "Batch [30/1563], Loss: 0.5744, Accuracy: 80.42%\n",
            "Batch [40/1563], Loss: 0.5502, Accuracy: 81.25%\n",
            "Batch [50/1563], Loss: 0.5279, Accuracy: 82.00%\n",
            "Batch [60/1563], Loss: 0.5243, Accuracy: 82.14%\n",
            "Batch [70/1563], Loss: 0.5153, Accuracy: 82.28%\n",
            "Batch [80/1563], Loss: 0.5115, Accuracy: 82.42%\n",
            "Batch [90/1563], Loss: 0.5067, Accuracy: 82.53%\n",
            "Batch [100/1563], Loss: 0.5062, Accuracy: 82.62%\n",
            "Batch [110/1563], Loss: 0.5047, Accuracy: 82.56%\n",
            "Batch [120/1563], Loss: 0.5077, Accuracy: 82.32%\n",
            "Batch [130/1563], Loss: 0.5166, Accuracy: 82.07%\n",
            "Batch [140/1563], Loss: 0.5227, Accuracy: 81.85%\n",
            "Batch [150/1563], Loss: 0.5240, Accuracy: 81.81%\n",
            "Batch [160/1563], Loss: 0.5280, Accuracy: 81.62%\n",
            "Batch [170/1563], Loss: 0.5263, Accuracy: 81.64%\n",
            "Batch [180/1563], Loss: 0.5242, Accuracy: 81.81%\n",
            "Batch [190/1563], Loss: 0.5274, Accuracy: 81.73%\n",
            "Batch [200/1563], Loss: 0.5285, Accuracy: 81.81%\n",
            "Batch [210/1563], Loss: 0.5289, Accuracy: 81.73%\n",
            "Batch [220/1563], Loss: 0.5330, Accuracy: 81.52%\n",
            "Batch [230/1563], Loss: 0.5320, Accuracy: 81.52%\n",
            "Batch [240/1563], Loss: 0.5300, Accuracy: 81.52%\n",
            "Batch [250/1563], Loss: 0.5310, Accuracy: 81.38%\n",
            "Batch [260/1563], Loss: 0.5346, Accuracy: 81.27%\n",
            "Batch [270/1563], Loss: 0.5340, Accuracy: 81.33%\n",
            "Batch [280/1563], Loss: 0.5396, Accuracy: 81.16%\n",
            "Batch [290/1563], Loss: 0.5449, Accuracy: 80.98%\n",
            "Batch [300/1563], Loss: 0.5452, Accuracy: 81.05%\n",
            "Batch [310/1563], Loss: 0.5449, Accuracy: 81.04%\n",
            "Batch [320/1563], Loss: 0.5442, Accuracy: 81.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 그래프\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\")\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Train Accuracy\")\n",
        "plt.title(\"Train Loss and Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.savefig(\"train_results.png\")  # 그래프 저장\n",
        "plt.show()\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), \"inceptionv2_trained.pth\")\n",
        "print(\"Model saved to inceptionv2_trained.pth\")"
      ],
      "metadata": {
        "id": "6CkhuSWxAzjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}